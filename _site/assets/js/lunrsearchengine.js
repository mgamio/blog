
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "About me",
    "body": "    I was born in Lima, Peru, where I studied for 5 years and obtained a degree in System Engineering. I have been working 20 years as a Software Engineer for several companies from different economic sectors such as Government, Financial, Industrial, Educative, Consulting, Retail, and Research.      A little more. . . :   I have been programming in several languages such as Java, C, Cobol, C#, Visual Basic, PHP, Prolog, Python, PL/SQL and JScript. My tasks have been related to Software Development, stages of Analysis, Design, Testing, and Deployment.   During 8 years, I worked as a System Analyst for the Bank Sector. Since 2014, I am working as a Software Engineer in a B2B company in Berlin, Germany.   This is my blog site to share my knowledge and experience in everyday situations that we, as developers, face daily. At the moment, I am passionate about the following things:      Clean Code   Spring Framework   RESTful Web Services   Automated testing   Software Design   Software Architecture   Distributed Systems   Data Structure and Algorithms	 Object-Oriented Programming	 Cloud Computing   Learning new technologies  	       	 Buy me a coffee   Thank you for your support! Your donation helps me to maintain and improve codersite.                         Understand the basics of common data structures and algorithms and apply them to real questions.    	 I want this	    	    Software design principles are guidelines that will help you make your system design resilient to future changes.    	 I want this	     Follow me on: "
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/impressum",
    "title": "Impressum",
    "body": "            Impressum      codersite is run by Moises Gamio 						Address: Romain-rolland Str 13089 Berlin, Germany 			Email: codersitedev@gmail. com 			Tax number: 32/300/01607       	          Content policy:       The content published on this website is original, clear, concise, and examples are based on the author's personal experience. 			Whenever necessary, I refer links to the sources for more in-depth information. 			I usually improve the contents based on users feedback 			      	          Advertising policy:       I use affiliate links. When you click on those links and buy something, I earn a commission. In that way, you help me to support this website. 			      "
    }, {
    "id": 4,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                     							                                                                                                                    Understanding OOP concepts                              :               Understanding OOP concepts give you a solid foundation for making critical decisions about object-oriented software design. :                                                                                                                                                                       Moises Gamio                                20 May 2022                                                                                                                                                                                                                                              							                                                                                                                    Big O Notation and Analysis of Algorithms - coding interview                              :               Big O Notation is a mathematical notation that helps us analyze how complex an algorithm is in terms of time and space. When we build. . . :                                                                                                                                                                       Moises Gamio                                22 Jun 2020                                                                                                                                                    All Stories:                                                                                                     Optimize Java App Performance              :       When dealing with a monolithic Java application under heavy concurrent load that leads to issues like too many opened data pools, excessive resource consumption, performance degradation, and even system crashes,. . . :                                                                               Powered by AI                05 Dec 2023                                                                                                                                     Building a REST API Client              :       This guide walks you through creating a client application that consumes a RESTful web service. :                                                                               Moises Gamio                30 Sep 2023                                                                                                                                     REST API Overview              :       APIs (Application Programming Interfaces) enable communication and data exchange between systems. Among the various types of APIs, REST (Representational State Transfer) has emerged as a popular architectural style for building. . . :                                                                               Moises Gamio                29 Jun 2023                                                                                                                                     Best Startup Ideas to Make Money              :       There are many ideas that could be suitable for starting a successful startup, and the ideal one will depend on various factors such as your interests, skills, market demand, and. . . :                                                                               Moises Gamio                25 Mar 2023                                                                                                                                     What are the Software Design Principles              :       Software design principles are guidelines and best practices that help software developers create high-quality, maintainable, and efficient software. Here are some commonly recognized software design principles::                                                                               Moises Gamio                22 Feb 2023                                                                                                                                     How to implement Rate Limiting              :       A rate-limiting system controls the rate of traffic sent or received on a network interface. APIs will use rate-limiting techniques to control how many times application Clients are allowed to. . . :                                                                               Moises Gamio                02 Feb 2023                                               &laquo; Prev       1        2        3        4        5      Next &raquo; "
    }, {
    "id": 5,
    "url": "http://localhost:4000/policy",
    "title": "Privacy policy",
    "body": "            Privacy policy      This policy describes the personal data that we collect, how we use and share it, your rights and choices. 			If you have additional questions or require more information about our Privacy Policy, do not hesitate to contact us.       	          Consent:       By using our website, you hereby consent to our Privacy Policy and agree to its terms.       	          Information we collect:       If you contact us directly, we may receive additional information about you such as your name, email address, phone number, the contents of the message and/or attachments you may send us, and any other information you may choose to provide.       	          How we use your information:       We use the information we collect in various ways, including to: 							Improve, personalize, and expand our website				Understand and analyze how you use our website				Develop new services, features, and functionality				Communicate with you to provide you with updates and other information relating to the website, i. e. , new posts. 				Find and prevent fraud			      	          Log Files:       codersite. dev follows a standard procedure of using log files. These files log visitors when they visit websites. All hosting companies do this and a part of hosting services' analytics. The information collected by log files include internet protocol (IP) addresses, browser type, Internet Service Provider (ISP), date and time stamp, referring/exit pages, and possibly the number of clicks. These are not linked to any information that is personally identifiable. The purpose of the information is for analyzing trends, administering the site, tracking users' movement on the website, and gathering demographic information       	          Google DoubleClick DART Cookie:       Google is one of a third-party vendor on our site. It also uses cookies, known as DART cookies, to serve ads to our site visitors based upon their visit to www. website. com and other sites on the internet. However, visitors may choose to decline the use of DART cookies by visiting the Google ad and content network Privacy Policy at the following URL – https://policies. google. com/technologies/ads       	          Google Analytics:       This website also uses Google Analytics to analyse how and when you visit our website in order to be able to understand your needs and improve your experience on our website. By using our website, you agree that your information is used for these purposes however your information is kept anonymous unless you specifically agree otherwise. 			You can opt out of these features by downloading the following opt-out browser add-on: 			https://tools. google. com/dlpage/gaoptout 					Please check that your browser supports such an add-on.       	          Advertising Partners Privacy Policies:       You may consult this list to find the Privacy Policy for each of the advertising partners of codersite. dev. 			Third-party ad servers or ad networks uses technologies like cookies, JavaScript, or Web Beacons that are used in their respective advertisements and links that appear on codersite. dev, which are sent directly to users' browser. They automatically receive your IP address when this occurs. These technologies are used to measure the effectiveness of their advertising campaigns and/or to personalize the advertising content that you see on websites that you visit. 			Note that codersite. dev has no access to or control over these cookies that are used by third-party advertisers.       	          Third Party Privacy Policies:       codersite. dev's Privacy Policy does not apply to other advertisers or websites. Thus, we are advising you to consult the respective Privacy Policies of these third-party ad servers for more detailed information. It may include their practices and instructions about how to opt-out of certain options. 			You can choose to disable cookies through your individual browser options. To know more detailed information about cookie management with specific web browsers, it can be found at the browsers' respective websites.       	    			CCPA Privacy Rights (Do Not Sell My Personal Information): 			Under the CCPA, among other rights, California consumers have the right to: 			Request that a business that collects a consumer's personal data disclose the categories and specific pieces of personal data that a business has collected about consumers. 			Request that a business delete any personal data about the consumer that a business has collected. 			Request that a business that sells a consumer's personal data, not sell the consumer's personal data. 			If you make a request, we have one month to respond to you. If you would like to exercise any of these rights, please contact us.       	    			GDPR Data Protection Rights: 			We would like to make sure you are fully aware of all of your data protection rights. Every user is entitled to the following: 			The right to access – You have the right to request copies of your personal data. We may charge you a small fee for this service. 			The right to rectification – You have the right to request that we correct any information you believe is inaccurate. You also have the right to request that we complete the information you believe is incomplete. 			The right to erasure – You have the right to request that we erase your personal data, under certain conditions. 			The right to restrict processing – You have the right to request that we restrict the processing of your personal data, under certain conditions. 			The right to object to processing – You have the right to object to our processing of your personal data, under certain conditions. 			The right to data portability – You have the right to request that we transfer the data that we have collected to another organization, or directly to you, under certain conditions. 			If you make a request, we have one month to respond to you. If you would like to exercise any of these rights, please contact us.       	    			Children's Information: 			Another part of our priority is adding protection for children while using the internet. We encourage parents and guardians to observe, participate in, and/or monitor and guide their online activity. 			codersite. dev does not knowingly collect any Personal Identifiable Information from children under the age of 13. If you think that your child provided this kind of information on our website, we strongly encourage you to contact us immediately and we will do our best efforts to promptly remove such information from our records.       "
    }, {
    "id": 6,
    "url": "http://localhost:4000/recommended.html",
    "title": "Recommended",
    "body": ""
    }, {
    "id": 7,
    "url": "http://localhost:4000/termsOfService",
    "title": "Terms and Conditions",
    "body": "            Terms and Conditions      			Last updated: January 17, 2022 			Please read these terms and conditions carefully before using Our Service. 			Interpretation and Definitions: 			Interpretation: 			The words of which the initial letter is capitalized have meanings defined under the following conditions. The following definitions shall have the same meaning regardless of whether they appear in singular or in plural. 			Definitions: 			For the purposes of these Terms and Conditions: 									Affiliate means an entity that controls, is controlled by or is under common control with a party, where &quot;control&quot; means ownership of 50% or more of the shares, equity interest or other securities entitled to vote for election of directors or other managing authority. 									Country refers to: Berlin, Germany 									Company (referred to as either &quot;the Company&quot;, &quot;We&quot;, &quot;Us&quot; or &quot;Our&quot; in this Agreement) refers to codersite. 									Device means any device that can access the Service such as a computer, a cellphone or a digital tablet. 									Service refers to the Website. 									Terms and Conditions (also referred as &quot;Terms&quot;) mean these Terms and Conditions that form the entire agreement between You and the Company regarding the use of the Service. This Terms and Conditions agreement has been created with the help of the Terms and Conditions Template. 									Third-party Social Media Service means any services or content (including data, information, products or services) provided by a third-party that may be displayed, included or made available by the Service. 									Website refers to codersite, accessible from https://codersite. dev 									You means the individual accessing or using the Service, or the company, or other legal entity on behalf of which such individual is accessing or using the Service, as applicable. 									Acknowledgment: 			These are the Terms and Conditions governing the use of this Service and the agreement that operates between You and the Company. These Terms and Conditions set out the rights and obligations of all users regarding the use of the Service. 			Your access to and use of the Service is conditioned on Your acceptance of and compliance with these Terms and Conditions. These Terms and Conditions apply to all visitors, users and others who access or use the Service. 			By accessing or using the Service You agree to be bound by these Terms and Conditions. If You disagree with any part of these Terms and Conditions then You may not access the Service. 			You represent that you are over the age of 18. The Company does not permit those under 18 to use the Service. 			Your access to and use of the Service is also conditioned on Your acceptance of and compliance with the Privacy Policy of the Company. Our Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your personal information when You use the Application or the Website and tells You about Your privacy rights and how the law protects You. Please read Our Privacy Policy carefully before using Our Service. 			Links to Other Websites: 			Our Service may contain links to third-party web sites or services that are not owned or controlled by the Company. 			The Company has no control over, and assumes no responsibility for, the content, privacy policies, or practices of any third party web sites or services. You further acknowledge and agree that the Company shall not be responsible or liable, directly or indirectly, for any damage or loss caused or alleged to be caused by or in connection with the use of or reliance on any such content, goods or services available on or through any such web sites or services. 			We strongly advise You to read the terms and conditions and privacy policies of any third-party web sites or services that You visit. 			Termination: 			We may terminate or suspend Your access immediately, without prior notice or liability, for any reason whatsoever, including without limitation if You breach these Terms and Conditions. 			Upon termination, Your right to use the Service will cease immediately. 			Limitation of Liability: 			Notwithstanding any damages that You might incur, the entire liability of the Company and any of its suppliers under any provision of this Terms and Your exclusive remedy for all of the foregoing shall be limited to the amount actually paid by You through the Service or 100 USD if You haven't purchased anything through the Service. 			To the maximum extent permitted by applicable law, in no event shall the Company or its suppliers be liable for any special, incidental, indirect, or consequential damages whatsoever (including, but not limited to, damages for loss of profits, loss of data or other information, for business interruption, for personal injury, loss of privacy arising out of or in any way related to the use of or inability to use the Service, third-party software and/or third-party hardware used with the Service, or otherwise in connection with any provision of this Terms), even if the Company or any supplier has been advised of the possibility of such damages and even if the remedy fails of its essential purpose. 			Some states do not allow the exclusion of implied warranties or limitation of liability for incidental or consequential damages, which means that some of the above limitations may not apply. In these states, each party's liability will be limited to the greatest extent permitted by law. 			&quot;AS IS&quot; and &quot;AS AVAILABLE&quot; Disclaimer: 			The Service is provided to You &quot;AS IS&quot; and &quot;AS AVAILABLE&quot; and with all faults and defects without warranty of any kind. To the maximum extent permitted under applicable law, the Company, on its own behalf and on behalf of its Affiliates and its and their respective licensors and service providers, expressly disclaims all warranties, whether express, implied, statutory or otherwise, with respect to the Service, including all implied warranties of merchantability, fitness for a particular purpose, title and non-infringement, and warranties that may arise out of course of dealing, course of performance, usage or trade practice. Without limitation to the foregoing, the Company provides no warranty or undertaking, and makes no representation of any kind that the Service will meet Your requirements, achieve any intended results, be compatible or work with any other software, applications, systems or services, operate without interruption, meet any performance or reliability standards or be error free or that any errors or defects can or will be corrected. 			Without limiting the foregoing, neither the Company nor any of the company's provider makes any representation or warranty of any kind, express or implied: (i) as to the operation or availability of the Service, or the information, content, and materials or products included thereon; (ii) that the Service will be uninterrupted or error-free; (iii) as to the accuracy, reliability, or currency of any information or content provided through the Service; or (iv) that the Service, its servers, the content, or e-mails sent from or on behalf of the Company are free of viruses, scripts, trojan horses, worms, malware, timebombs or other harmful components. 			Some jurisdictions do not allow the exclusion of certain types of warranties or limitations on applicable statutory rights of a consumer, so some or all of the above exclusions and limitations may not apply to You. But in such a case the exclusions and limitations set forth in this section shall be applied to the greatest extent enforceable under applicable law. 			Governing Law: 			The laws of the Country, excluding its conflicts of law rules, shall govern this Terms and Your use of the Service. Your use of the Application may also be subject to other local, state, national, or international laws. 			Disputes Resolution: 			If You have any concern or dispute about the Service, You agree to first try to resolve the dispute informally by contacting the Company. 			For European Union (EU) Users: 			If You are a European Union consumer, you will benefit from any mandatory provisions of the law of the country in which you are resident in. 			United States Legal Compliance: 			You represent and warrant that (i) You are not located in a country that is subject to the United States government embargo, or that has been designated by the United States government as a &quot;terrorist supporting&quot; country, and (ii) You are not listed on any United States government list of prohibited or restricted parties. 			Severability and Waiver: 			Severability: 			If any provision of these Terms is held to be unenforceable or invalid, such provision will be changed and interpreted to accomplish the objectives of such provision to the greatest extent possible under applicable law and the remaining provisions will continue in full force and effect. 			Waiver: 			Except as provided herein, the failure to exercise a right or to require performance of an obligation under these Terms shall not effect a party's ability to exercise such right or require such performance at any time thereafter nor shall the waiver of a breach constitute a waiver of any subsequent breach. 			Translation Interpretation: 			These Terms and Conditions may have been translated if We have made them available to You on our Service. 			You agree that the original English text shall prevail in the case of a dispute. 			Changes to These Terms and Conditions: 			We reserve the right, at Our sole discretion, to modify or replace these Terms at any time. If a revision is material We will make reasonable efforts to provide at least 30 days' notice prior to any new terms taking effect. What constitutes a material change will be determined at Our sole discretion. 			By continuing to access or use Our Service after those revisions become effective, You agree to be bound by the revised terms. If You do not agree to the new terms, in whole or in part, please stop using the website and the Service. 			Contact Us: 			If you have any questions about these Terms and Conditions, You can contact us: 						By email: codersitedev@gmail. com				      	"
    }, {
    "id": 8,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 9,
    "url": "http://localhost:4000/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 10,
    "url": "http://localhost:4000/page4/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 11,
    "url": "http://localhost:4000/page5/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 12,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ &#8220;sitemap. xml&#8221;   absolute_url }}   "
    }, {
    "id": 13,
    "url": "http://localhost:4000/optimize-java-app-performance/",
    "title": "Optimize Java App Performance",
    "body": "2023/12/05 - When dealing with a monolithic Java application under heavy concurrent load that leads to issues like too many opened data pools, excessive resource consumption, performance degradation, and even system crashes, several strategies can be employed to address the problem. Here are some recommendations: 1. -Optimize Database Connection Handling:  Use connection pooling to reduce the overhead of creating and managing new database connections for each request. This ensures the reuse of established connections, minimizing the impact on database resources and improving overall performance.  Tune the connection pool settings to handle the expected concurrent load.  Ensure that connections are being released properly after usage to prevent connection leaks. 2. -Implement Caching:  Introduce caching mechanisms to reduce the load on the database and improve response times.  Cache frequently accessed data or query results to serve subsequent requests without hitting the database. 3. -Load Balancing:  Deploy load balancing to distribute incoming requests across multiple instances of the application.  This helps in scaling horizontally by adding more servers to handle increased load. 4. -Scale Horizontally:  Consider deploying the application on multiple servers or instances to distribute the load.  Use a load balancer to evenly distribute requests among the different instances. 5. -Asynchronous Processing:  Identify tasks that can be performed asynchronously and offload them to background processes or message queues.  This helps in freeing up resources to handle more incoming requests. 6. -Optimize Code and Queries:  Optimize database queries by using appropriate indexes, avoiding unnecessary JOINs, and using efficient data types. This ensures that database queries are executed quickly and efficiently, reducing the overall processing time for requests.  Identify and eliminate bottlenecks in the code and database interactions. 7. -Monitoring and Profiling:  Implement monitoring and profiling tools to identify performance bottlenecks and areas for improvement.  Implement comprehensive logging to track request patterns, resource usage, and error occurrences.  Analyze logs, metrics, and performance data to make informed decisions.  8. -Vertical Scaling:  Consider upgrading hardware resources (CPU, RAM) on the existing server to handle increased load.  This is known as vertical scaling and can be a temporary solution while you work on horizontal scaling. 9. -Implement Content Delivery Networks (CDNs):  Utilize a Content Delivery Network (CDN) to cache static content like images, JavaScript, and CSS. This offloads the processing of static content from the application server, improving performance and reducing server load. 10. -Fault Tolerance and Resilience:  Enhance the application’s fault tolerance by implementing mechanisms such as retry policies.  Implement circuit breakers to monitor the health of external services or APIs that your application relies on. If a service becomes unavailable or unresponsive, the circuit breaker can temporarily disable requests to that service, preventing cascading failures and ensuring application stability.  Ensure the application can gracefully handle failures and recover without affecting the user experience. 11. -Implement Autoscalers:  Employ auto-scaling mechanisms to automatically adjust the number of application servers based on real-time demand. This ensures that the system has sufficient resources to handle the current load while avoiding resource wastage when traffic is low. 12. -Modularization and Microservices:  If appropriate, consider breaking down the monolith into microservices. Microservices architecture decomposes a monolithic application into smaller, independent services, enabling better scaling, isolation, and fault tolerance. This modular approach can significantly improve handling of concurrent requests and overall application resilience.  Microservices architecture allows you to scale individual services based on their specific requirements. 13. -Resource Cleanup and Management:  Ensure proper resource cleanup after each request to prevent resource leaks.  Closely monitor resource usage, including CPU, memory, and network traffic, to identify potential bottlenecks. This allows you to take proactive measures to address resource-intensive tasks and optimize performance. 14. -Review and Refactor Code:  Conduct a thorough code review to identify areas that can be refactored for better performance.  Identify and eliminate unnecessary code, optimize data access patterns, and minimize resource-intensive operations.  Consider rewriting or optimizing critical sections of the code. 15. -Review Third-Party Dependencies:  Evaluate and update third-party libraries and dependencies. Outdated or inefficient libraries can contribute to performance issues. 16. -Tune Java Virtual Machine (JVM) Settings:  Adjust JVM settings, such as heap size and garbage collection parameters, to optimize memory management and overall performance. 17. -Implement Rate Limiting:  Rate limiting controls the frequency of requests from a particular client or IP address. This helps prevent a single user from overwhelming the system and ensures fair access for all users. 18. -Consider Cloud Services:  Explore cloud services that offer scalable infrastructure solutions.  Cloud platforms often provide tools for easy scalability, load balancing, and resource management. By implementing a combination of these strategies, you can effectively manage concurrent requests in your Java application server and ensure the stability, performance, and scalability of your application under heavy load conditions. Remember that the appropriate solution may depend on the specific characteristics and requirements of your application. It’s often beneficial to combine multiple strategies for a comprehensive approach to scalability and performance optimization. Regularly monitor the application’s performance and make adjustments as needed.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev  "
    }, {
    "id": 14,
    "url": "http://localhost:4000/building-rest-api-client/",
    "title": "Building a REST API Client",
    "body": "2023/09/30 - This guide walks you through creating a client application that consumes a RESTful web service. We will build a custom client code to test the rate-limiting algorithm implemented at an API Server. Client application uses Spring’s RestTemplate, a synchronous client to perform HTTP requests. We want to implement several calls to different endpoints. We create an interface with only one method. 123456789public interface IClientAPI { static String apiHost =  &lt;here_your_api_host&gt; ; static String tokenUri = apiHost +  /oauth/token ; static String url = apiHost +  /v1/ ;  public void callEndpoint() throws Exception;}First, we consume data from the Supplier endpoint. So, we implement the above method. 123456789101112131415161718192021222324252627282930public final class GetSuppliers implements IClientAPI { private static OAuth2RestTemplate restTemplate; private static HttpHeaders headers; private static final int NRO_REQUESTS =60; public GetSuppliers(String clientId, String secret) {  headers = new HttpHeaders();  restTemplate = buildRestTemplate(clientId, secret); }	 public void callEndpoint() throws Exception {  for (int idx = 1; idx &lt;= NRO_REQUESTS; idx++) {   try {    String urlEndpoint = url +  suppliers ;    headers. set( NroClientRequest , String. valueOf(idx));    HttpEntity&lt;String&gt; entity = new HttpEntity&lt;String&gt;(headers);        ResponseEntity&lt;List&lt;Supplier&gt;&gt; responseEntity = restTemplate. exchange(urlEndpoint, HttpMethod. GET, entity, List. class);    logger. info( X-Rate-Limit-Remaining :   + responseEntity. getHeaders(). getFirst( X-Rate-Limit-Remaining ));   } catch (Exception e) {    logger. error( error:   + e. getMessage());   }  }  } }Secondly, we retrieve data from the Buyer endpoint. So, we need a new custom implementation for the callEndpoint method. 1234567891011121314151617181920212223public final class GetBuyers implements IClientAPI { private static final int NRO_REQUESTS =140; //code omitted for brevity public void callEndpoint() throws Exception {  for (int idx = 1; idx &lt;= NRO_REQUESTS; idx++) {   try {    String urlEndpoint = url +  buyers ;    headers. set( NroClientRequest , String. valueOf(idx));    HttpEntity&lt;String&gt; entity = new HttpEntity&lt;String&gt;(headers);        ResponseEntity&lt;List&lt;Buyer&gt;&gt; responseEntity = restTemplate. exchange(urlEndpoint, HttpMethod. GET, entity, List. class);    logger. info( X-Rate-Limit-Remaining :   + responseEntity. getHeaders(). getFirst( X-Rate-Limit-Remaining ));   } catch (Exception e) {    logger. error( error:   + e. getMessage());   }  }  } }We will simulate a more realistic scenario where client requests arrive concurrently to the API Server. ForkJoinPool class is an ExecutorService that helps speed up parallel processing by attempting to use all available processor cores. 12345678910111213141516171819202122232425public class RESTFulParallelClientsTest { public static void main(String[] args) {  IClientAPI iClientAPI_suppliers = new GetSuppliers( &lt;here_clientId&gt; , &lt;here_secret&gt; );  IClientAPI iClientAPI_buyers = new GetBuyers( &lt;here_other_clientId&gt; , &lt;here_other_secret&gt; );  Callable&lt;Void&gt; runnableTask1 = runnableTask(iClientAPI_suppliers);  Callable&lt;Void&gt; runnableTask2 = runnableTask(iClientAPI_buyers);		  ForkJoinPool. commonPool(). invokeAll(asList(   runnableTask1   ,runnableTask2   )); } private static Callable&lt;Void&gt; runnableTask(IClientAPI iClientAPI) {  return () -&gt; {   iClientAPI. callEndpoint();   return null;  }; }}Suppose the API Server set up a limit of 90 requests per minute for the buyer’s endpoint. Then, request number 91 is refused, and the client receives an HTTP Error code of 429. 1216:10:42. 454 [main] INFO RESTFulParallelClientsTest - https://api_host/v1/buyers Client request nro: 9116:10:42. 542 [main] INFO RESTFulParallelClientsTest - 429 { title : Too many request , status :429, detail : X-Rate-Limit-Retry-After-Seconds: 37 , path : /v1/buyers client: codersite. dev ,  timeStamp :1696428642515}With this test, you can simultaneously send thousands of requests to all your API endpoints. You can monitor your thread pool at the application server and see how the rate limit algorithm refuses all requests that exceed the rate limit quote. Please donate if you find this content valuable.    "
    }, {
    "id": 15,
    "url": "http://localhost:4000/rest-api-overview/",
    "title": "REST API Overview",
    "body": "2023/06/29 - APIs (Application Programming Interfaces) enable communication and data exchange between systems. Among the various types of APIs, REST (Representational State Transfer) has emerged as a popular architectural style for building web services. This article will delve into the fundamental concepts of REST API, its principles, its benefits in modern web development, and how to design a RESTful API. What is an API?: An API is an interface with defined functionalities that a software program presents to other programs and, in the case of web APIs, to the rest of the world via the Internet. APIs are the building blocks that allow interoperability between businesses on the web. Companies implement APIs to expose internal business processes and data to new customers and partners. APIs are how food data containing information about allergens are shared with hundreds of restaurant apps specializing in their presentation to final customers. We must create programs (API Servers) that serve data and other programs (API Clients) that consume/manipulate that data, as shown in the following figure.  Every company can implement Servers’ and Clients’ APIs using different programming languages, caches, proxies, and security mechanisms. They can choose monolithic or microservices architectures deployed in several application servers or cloud providers. But how can all these heterogeneous components communicate with each other? The only answer is that they use a common language: the same semantics as the HTTP protocol. In this context, semantic means the interpretation we give every HTTP method. We create a kind of API program called Web Service to support this interoperable machine-to-machine interaction over a network. To implement efficiently API Servers or API Clients, you must understand the basic concepts of a REST API. What is REST API?: REST API is an architectural style that defines a set of guidelines for creating web services. It stands for Representational State Transfer and emphasizes a stateless, client-server communication model. REST APIs use HTTP (Hypertext Transfer Protocol) as the primary protocol for data transmission and rely on standard operations such as GET, POST, PUT, and DELETE to perform actions on resources. The Hypertext Transfer Protocol (HTTP) is a stateless application-level protocol for distributed, collaborative, hypertext information systems. Resources: In REST API, a resource is the information or data exposed through the web service. Resources can be entities such as users, suppliers, articles, or any other data entity that can be uniquely identified. Each resource on the Web is typically represented by a URL (Uniform Resource Locator) or endpoint defining a globally unique address. Giving something a URL turns it into a resource. In a business context, the following endpoint retrieves a representation of an array of article data under the following URL. 12GET /api/v1/articles HTTP/1. 1Host: codersite. devRepresentations: We have defined an article as an HTTP resource but cannot transmit a physical article over the Internet. But as an information resource, we can send It over the Internet. The information must be helpful for the client. That’s a representation, a machine-readable description of the current state of a resource. 12345678HTTP/1. 1 200 OKContent-Type: application/json{ articleID : 12121, articleName :  Potatoes  articlePrice : 12,3 articleDeliveryDate : 20230910}The server sends (because of GET requests from the client) a representation describing the state of a resource. The client sends (through a POST, PUT, or PATCH request) a representation describing the state it would like the resource to have. That’s representational state transfer. Uniform Interface: A fundamental principle of REST API is the uniform interface, which establishes a standardized way of interacting with resources. It encompasses several constraints, including:    Identification of resources: Resources should be uniquely identified by URIs.     Stateless communication: Each request from the client to the server should contain all the necessary information to process the request without relying on the server’s previous state.     Manipulation of resources through representations: Resources can be accessed and modified through representations, such as JSON or XML.     Self-descriptive messages: Requests and responses should include sufficient metadata to describe the meaning and format of the data.     Hypermedia as the engine of application state (HATEOAS): The API should provide links to related resources, allowing clients to navigate the application’s state.   HTTP Methods: API clients can interact with APIs by sending HTTP methods to perform actions on resources. The four commonly used HTTP methods are: GET Retrieves a representation of a resource or a collection of resources. 12345678910111213141516171819202122232425GET /api/v1/suppliers HTTP/1. 1Host: codersite. devHTTP/1. 1 200 OKContent-Type: application/json{  suppliers  : {   supplier  : [   {     supplierId : 1881,     supplierName :  ACME      supplierCurrency :  EUR    },   {     supplierId : 132,     supplierName :  ROYAL      supplierCurrency :  EUR    },   .    .   ] },  resultCountTotal  : 980}Even when a GET method is defined as a safe HTTP method, your application MUST ensure that it never changes the resource state. The success response code to a GET request is 200 (OK). POST Creates a new resource. When a client sends a POST request, it sends a representation of the resource it wants to create that corresponds with the semantics defined for the endpoint. 123456789POST /api/v1/buyers HTTP/1. 1Content-Type: application/jsonHost: codersite. dev{  buyerName  :  XYZ Restaurant ,  buyerContact  :  Mr Bond ,  buyerAddress  :  Berliner strasse 12 ,}If you include an extra attribute in the body request not defined in the endpoint representation, you probably receive an Error from the server. The success response code to a POST request is 201 (Created). PUT Updates an existing resource or creates it if it doesn’t exist. The client usually takes the representation from a GET request, modifies it, and sends it back as the body of a PUT request. 123456789PUT /api/v1/buyers/{buyerId} HTTP/1. 1Content-Type: application/jsonHost: codersite. dev{  buyerName  :  XYZ Restaurant ,  buyerContact  :  Herr Olaf ,  buyerAddress  :  Berliner strasse 12 ,}The success response code to a PUT request is 200 (OK). DELETE Removes a resource from the server. 123DELETE /api/v1/buyers/{buyerId} HTTP/1. 1Content-Type: application/jsonHost: codersite. devThe success response code to a DELETE request is 204 (No Content). Common HTTP Method Properties: Safe Methods A Request method is safe when it does not change the state of a resource on the API Server. The GET, HEAD, OPTIONS, and TRACE methods are defined to be safe. Idempotent Methods A request method is idempotent when multiple identical requests have the same effect on the API Server. The PUT, and DELETE methods are defined to be idempotent. Request and Response: REST API requests and responses are typically formatted in JSON (JavaScript Object Notation) or XML (eXtensible Markup Language). Requests consist of an HTTP method, headers, and, optionally, a request body containing data. Responses include an HTTP status code indicating the outcome of the request, along with the response body containing the requested resource or an error message. Common error HTTP status codes include:    400 Bad Request. This means that client-request input is not well-formed. The response body will include an error providing further information.     401 Unauthorized. Missing or incorrect authentication credentials.     403 Forbidden. This means the user is authenticated, but it’s not allowed to access a resource.     404 Not Found. The requested resource could not be found but may be available in the future.     405 Method Not Allowed. Indicates that the method received in the request-line is known by the origin server but not supported by the target resource.     406 Not Acceptable. Returned when an invalid format is specified in the request     429 Too Many Requests. Indicates the user has sent too many requests in a given amount of time (“rate limiting”).     500 Internal Server Error. Something is broken.  Building a RESTful Web Service: Business requirement: A company wants to implement an API to allow Restaurants (represented as a buyer) to place orders at suppliers to get food articles delivered. The following figure shows a UML class diagram to conceptual model the application’s structure.  We use API endpoints and HTTP methods to define and implement the specific functional requirements. We should use the nouns representing the entity with the endpoint we’re retrieving or manipulating as the pathname 12GET /buyersA list of accessible buyers is givenIt is highly recommended to use the SwaggerHub editor to create a consistent API design compliant with the OpenAPI Specifications. Create a Free Account. While you are designing, SwaggerHub can generate documentation automatically, making it easy for both API consumers and internal users to learn and test your APIs. You can create a Client SDK for different programming languages from the Editor and generate the object model and API controllers on your server side. The following figure shows an example of how SwaggerHub generates the documentation.  We will use the Spring portfolio to build a RESTful service. Separation of REST controllers and business logic: Following the “separation of concerns” principle, we delegated the responsibility for managing all HTTP requests and responses to a REST Controller (BuyersApiController) and managing all business logic, mappings, and the database connection to a Service class (BuyersService). @RestController annotation tells that this Class describes endpoints that should be made available over the web to handle all HTTP requests. We inject the BuyersService dependency class into the BuyersApiController class using its constructor method. 123456789101112@RestController@Validatedpublic class BuyersApiController implements BuyersApi {	 private final BuyersService buyersService; @Autowired public BuyersApiController(  BuyersService buyersService) {  this. buyersService = buyersService; }}Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  The following listing shows common operations in a REST Controller. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Override@RequestMapping(value =  /api/v1/buyers , method = RequestMethod. POST)public ResponseEntity&lt;Buyer&gt; addBuyer(Buyer body) throws Exception {	 Buyer newBuyer = buyersService. addBuyer(body);		 return new ResponseEntity&lt;Buyer&gt;(newBuyer, HttpStatus. CREATED);}@Override@RequestMapping(value =  /api/v1/buyers/{buyerId} , method = RequestMethod. DELETE)public ResponseEntity&lt;Void&gt; deleteBuyer(Integer buyerId) throws Exception { buyersService. deleteBuyer(buyerId); return new ResponseEntity&lt;Void&gt;(HttpStatus. NO_CONTENT);}	@Override@RequestMapping(value =  /api/v1/buyers/{buyerId} , method = RequestMethod. GET)public ResponseEntity&lt;Buyer&gt; getBuyerById(Integer buyerId) throws Exception { Buyer buyer = buyersService. getBuyerById(buyerId);		 if (buyer == null)  throw new ResourceNotFoundException( The buyerId does not exist );		 return new ResponseEntity&lt;Buyer&gt;(buyer, HttpStatus. OK);}@Override@RequestMapping(value =  /api/v1/buyers/{buyerId} , method = RequestMethod. PUT)public ResponseEntity&lt;Buyer&gt; updateBuyer(Integer buyerId, Buyer body) throws Exception { Buyer updatedBuyer = buyersService. updateBuyer(buyerId, body);		 return new ResponseEntity&lt;Buyer&gt;(updatedBuyer, HttpStatus. OK);}@Override@RequestMapping(value =  /api/v1/buyers , method = RequestMethod. GET)public ResponseEntity&lt;List&lt;Buyer&gt;&gt; listBuyers( String buyerCompanyName,  String sortBy, String sortOrder,  Integer offset,  Integer limit) throws Exception { ListBuyersResponse response = buyersService. listBuyers(  buyerCompanyName, sortBy, sortOrder, offset, limit); HttpHeaders responseHeaders = new HttpHeaders(); responseHeaders. set( X-TotalResultCount , String. valueOf(response. getTotalResultCount()));   return new ResponseEntity&lt;List&lt;Buyer&gt;&gt;(response. getListBuyers(), responseHeaders, HttpStatus. OK);}	Include Loggers: Redirect the requests to the server logs. If you must fix any error your clients reported, you can always reproduce the original request and debug it in your backends. 12345678910@Override@RequestMapping(value =  /api/v1/buyers/{buyerId} , method = RequestMethod. DELETE)public ResponseEntity&lt;Void&gt; deleteBuyer(Integer buyerId) throws Exception { logger. info(request. getMethod() + UtilitiesService. REQUESTED_PARAMETERS + utilitiesService. getRequestURLWithQueryParam(request)); buyersService. deleteBuyer(buyerId); return new ResponseEntity&lt;Void&gt;(HttpStatus. NO_CONTENT);}We include a new dependency in your Api Controller: 123456789101112public class UtilitiesServiceImpl implements UtilitiesService {@Overridepublic String getRequestURLWithQueryParam(HttpServletRequest request) { StringBuffer requestURL = request. getRequestURL();  if (request. getQueryString() != null) {   requestURL. append('?'). append(request. getQueryString());  }  return requestURL. toString(); }}Even you can create statistics of how many requests by endpoint arrive per minute by implementing a hot-warm architecture in Elasticsearch. 1[12/4/23 15:48:27:888 CET] 00000121 SystemOut   INFO 19484 BuyersApiController : DELETE_REQUESTED_PARAMETERS: https://yourapidomain/api/v1/buyers/12345Benefits of REST API: REST APIs offer several advantages that contribute to their widespread adoption in modern web development:    Scalability: REST API’s stateless nature allows for horizontal scalability, where multiple servers can handle requests independently, improving performance and accommodating a growing user base.     Interoperability: REST APIs leverage standardized HTTP methods and formats, enabling communication between different systems regardless of their underlying technologies.     Simplicity and ease of use: REST APIs have a straightforward design, making them easy to understand, implement, and consume. Developers can quickly grasp the concepts and start building applications around the exposed resources.     Flexibility: REST APIs support various data formats and can be used with different client applications, including web browsers, mobile devices, and third-party services.  Conclusion: REST API concepts provide a foundation for building scalable, interoperable, and easily consumable web services. Understanding the principles of REST, such as resources, uniform interface, HTTP methods, and request/response formats, is crucial for designing and consuming RESTful APIs effectively. 			 &nbsp; Stay Connected!. Follow me to get my latest articles.                                 	"
    }, {
    "id": 16,
    "url": "http://localhost:4000/best-startup-ideas-to-make-money/",
    "title": "Best Startup Ideas to Make Money",
    "body": "2023/03/25 - There are many ideas that could be suitable for starting a successful startup, and the ideal one will depend on various factors such as your interests, skills, market demand, and resources available. However, here are some general ideas that could be worth considering:    Solve a problem: Identify a problem that people face and create a solution that meets their needs. This could be anything from a new app that simplifies a complicated task, to a product that makes everyday life easier.     Disrupt an industry: Look for an industry that could use some innovation and find a way to disrupt it. This could mean using technology to automate or streamline processes, or creating a new business model that challenges traditional ways of doing things.     Focus on a niche market: Identify a niche market with specific needs or preferences, and create a product or service that caters to those needs. This could be anything from a vegan meal delivery service to a website that connects remote workers with each other.     Market demand: It’s important to make sure there is actually a market for your product or service before investing too much time and money into it. Conduct market research to ensure that there is a demand for what you are offering.     Capitalize on a trend: Keep an eye on trends and capitalize on them before they become saturated. This could be anything from a new social media platform to a product that capitalizes on the latest wellness trend.     Create something new: Use your creativity and innovation to create something new that has never been done before. This could be anything from a new form of entertainment to a product that changes the way we live.     Passion: Starting a successful startup can be a long and challenging process, so it’s important to choose an idea that you are truly passionate about and committed to seeing through to fruition.  Remember that a successful startup is not just about having a great idea, but also executing it well, building a solid team, and creating a sustainable business model. The best startup ideas often come from a combination of creativity, innovation, and market research, so take your time to research and brainstorm before committing to an idea. "
    }, {
    "id": 17,
    "url": "http://localhost:4000/software-design-principles/",
    "title": "What are the Software Design Principles",
    "body": "2023/02/22 - Software design principles are guidelines and best practices that help software developers create high-quality, maintainable, and efficient software. Here are some commonly recognized software design principles:    SOLID: SOLID stands for Single Responsibility, Open-Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion. These five principles help developers create software that is modular, extensible, and easy to maintain.     DRY (Don’t Repeat Yourself): The DRY principle states that code should not be repeated unnecessarily. Instead, developers should use abstractions, modularization, and other techniques to reduce repetition and make code more maintainable.     KISS (Keep It Simple, Stupid): The KISS principle suggests that developers should strive for simplicity and avoid unnecessary complexity. This makes code easier to understand, maintain, and debug.     YAGNI (You Ain’t Gonna Need It): The YAGNI principle encourages developers to avoid writing code that may be needed in the future but is not necessary at present. This reduces complexity and saves time and effort.     Separation of Concerns: This principle suggests that different concerns, such as user interface, data storage, and business logic, should be separated and handled independently. This makes code more modular, easier to maintain, and less prone to errors.     Composition over Inheritance: This principle suggests that developers should prefer composition over inheritance when designing software. This makes code more flexible and extensible and reduces code duplication.     Law of Demeter (LoD): The Law of Demeter suggests that objects should only communicate with their immediate neighbors and not with objects further down the chain. This reduces coupling and makes code more maintainable.     Design Patterns: Design patterns are proven solutions to common software design problems. Developers can use design patterns to create software that is modular, flexible, and reusable.  These principles are not exhaustive, and there may be other principles that are relevant to specific types of software. However, these principles provide a solid foundation for creating high-quality, maintainable, and efficient software. Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 18,
    "url": "http://localhost:4000/rate-limit/",
    "title": "How to implement Rate Limiting",
    "body": "2023/02/02 - A rate-limiting system controls the rate of traffic sent or received on a network interface. APIs will use rate-limiting techniques to control how many times application Clients are allowed to call an API endpoint during a given time interval - Request Limiting. Traffic is allowed up to one specified rate, whereas traffic that exceeds that rate is denied – HTTP code 429. Reasons to implement Rate Limiting:    Avoid a denial-of-service (DoS) attack. So, the first principle here will be Availability for our distributed systems.     We must protect database functions that use expensive hardware resources when the API requests arrive concurrently or sequentially without limit.     Limiting Concurrent Requests.     Rate limiting is one of the solutions to prevent “Unrestricted Resource Consumption” API4:2023.  Token-bucket algorithm: The token-bucket algorithm is explained with the analogy of a bucket with finite capacity, into which tokens are added at a fixed rate. But it can’t fill up infinitely. If a token arrives when the bucket is complete, it’s discarded. On every request, n number of tokens are removed from the bucket. The request is rejected if there are fewer than n tokens in the bucket. When we have somebody that takes out tokens, we also need somebody that puts tokens into the bucket. The refiller periodically creates new tokens and puts them into the bucket.  About Bucket4j: Bucket4j is a Java rate limiting library implemented on top of ideas of the token-bucket algorithm. Maven Configuration: We need to add the bucket4j dependency to our pom. xml file. 12345&lt;dependency&gt;  &lt;groupId&gt;com. bucket4j&lt;/groupId&gt;  &lt;artifactId&gt;bucket4j-core&lt;/artifactId&gt;  &lt;version&gt;8. 1. 1&lt;/version&gt;&lt;/dependency&gt;You can implement a rate limiting for your clients based on subscription plans or even for each endpoint. For learning purposes, we implement a rate limit based on external IPs. Inspirational Quotes About Tech: We implement a web service allowing clients to retrieve a Random Quote about tech. Firstly, we define a Repository class to retrieve Quotes data from a text file, for example. Secondly, we define a Service class to manipulate the previous data and get a random Quote. Finally, we assemble all these components - dependencies - in a RestContoller class. 12345678910111213@RestController@RequestMapping( /v1 )public class QuoteController { @Autowired private QuoteService quoteService; @GetMapping(value =  /quotes/random , produces = MediaType. APPLICATION_JSON_VALUE) public Quote getQuote(HttpServletRequest httpServletRequest) throws Exception {  return quoteService. getRandomQuote(); }} Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  For more information on implementing RESTful web services, visit this link. Once you deploy the API service, you can request a random quote from a Web Client like Postman.  But in reality, web Clients are automated, especially in B2B integrations, where developers on the client side send hundreds or thousands of requests per minute to analyze random data during the implementation stage. We should implement a Rate Limiting Algorithm to protect our software infrastructure from unintentional requests that exceed the regular consumption of our web services. Implementing Spring MVC HandlerInterceptor: The preHandle method of a HandlerInterceptor Interface intercepts a client request and adds a preprocess. 123456789101112@Componentpublic class RateLimitInterceptor implements HandlerInterceptor {  @Override public boolean preHandle(HttpServletRequest request,   HttpServletResponse response, Object handler) throws Exception {  	//preprocess here  	return false; }}To detect an external IP, we implement the following method. 12345678910 private String getClientIP(HttpServletRequest request) {  String ip = request. getHeader( X-FORWARDED-FOR );  if (ip == null || ip. isEmpty()) {   ip = request. getRemoteAddr();  }  return ip; }To use the bucket4j library, we need to understand their terminology. Bucket is the Interface that defines the behavior of a rate-limiter - based on the Token Bucket algorithm. A bucket is created using a builder pattern. 123Bucket bucket = Bucket. builder() . addLimit(. . . ) . build();To add a Limit to the bucket, we define a Bandwidth denoted by the following terms. Capacity specifies how many tokens your bucket has. Refill specifies how fast tokens can be refilled after it was consumed from a bucket. If we choose the interval refill, the bucket will wait until the whole period is elapsed before regenerating the whole amount of tokens. 123// generates 10 tokens each minuteRefill. intervally(10, Duration. ofMinutes(1));For example, if we decide that one client request represents a token, and the client sends ten requests over the next 15 seconds, then the client must wait 45 seconds to send the following request; otherwise, the API rejects the request. We will see this implementation later. The following code defines a bucket with 10 tokens of capacity. 123456 private long capacity = 10; private long tokens = 10;  private final Bucket defaultBucket = Bucket. builder()  . addLimit(Bandwidth. classic(capacity, Refill. intervally(tokens, Duration. ofMinutes(1))))  . build();We need a hashMap to store the buckets corresponding to each external IP. And we also need a variable that defines how many tokens we can consume from the bucket when a request arrives. 12 private final Map&lt;String, Bucket&gt; buckets = new ConcurrentHashMap&lt;&gt;(); private final long tokensToConsumeByDefault = 1;With all the pieces in place, we implement request preprocessing inside the preHandle method. 123456789101112131415161718192021222324252627@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {						   String clientIP = getClientIP(request); Bucket bucketByClientIP; if (buckets. containsKey(clientIP)) {  bucketByClientIP = buckets. get(clientIP); } else {  bucketByClientIP = this. defaultBucket;  buckets. put(clientIP, bucketByClientIP); } ConsumptionProbe probe = bucketByClientIP. tryConsumeAndReturnRemaining(this. tokensToConsumeByDefault); if (probe. isConsumed()) {  response. addHeader( X-Rate-Limit-Remaining ,   Long. toString(probe. getRemainingTokens()));  return true; } response. setStatus(HttpStatus. TOO_MANY_REQUESTS. value()); // 429 response. addHeader( X-Rate-Limit-Retry-After-Milliseconds ,  Long. toString(TimeUnit. NANOSECONDS. toMillis(probe. getNanosToWaitForRefill()))); return false;}The magic of this library is in the isConsumed() method. After asking the bucket to consume a token from the basket, we test whether the token was consumed. If true, the limit was not exceeded, and the API allows the client to consume the endpoint. Otherwise, the limit was exceeded, and we rejected the request, returning an HTTP error code of 429 to the client.  We need to register our RateLimitInterceptor class by extending the WebMvcConfigurerAdapter class. 1234567891011@Configurationpublic class InterceptorConfig extends WebMvcConfigurerAdapter { @Autowired RateLimitInterceptor rateLimitInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) {  registry. addInterceptor(rateLimitInterceptor); }}After you send ten requests, the eleventh request is rejected, and the web client must wait for around 7 seconds, as shown in the following example.  Offering valuable content through your API can also motivate external developers or companies to pay more for leveraging the API. When they exceed the ten requests by default, they subscribe to plans. Depending on how your software infrastructure is built, you can define plans with access to all API endpoints or a clientId+endpoint combination for example. If you dont know the actual request consumption from your users, you can install Elasticsearch and monitor the number of requests per minute daily. Read here. You can use these ideas when trying to implement rate limiting with Redis or with AWS. You can download the code from the following link Rate limit In my next post, we will build an automated web client with random data to test the rate limit algorithm. Follow me! 			 &nbsp; Stay Connected!. Follow me to get my latest articles.                                 	"
    }, {
    "id": 19,
    "url": "http://localhost:4000/soft-skills-software-development/",
    "title": "What are the Soft Skills in Software Development",
    "body": "2023/01/22 - Soft skills are the personal attributes that enable individuals to interact effectively and harmoniously with others. In software development, having strong soft skills is just as important as technical skills. Here are some examples of soft skills that are valuable in software development:    Communication: Good communication skills are essential for effective collaboration between developers, project managers, and other stakeholders. This includes the ability to communicate technical information clearly and concisely, as well as the ability to listen actively and ask questions.     Problem-solving: In software development, problems are inevitable. A developer with strong problem-solving skills can quickly identify issues and develop effective solutions.     Teamwork: Successful software development requires a collaborative effort. Team players can work effectively with others, understand their role within a team, and are willing to lend a hand when needed.     Adaptability: The ability to adapt to new technologies, processes, and challenges is crucial in software development, where change is a constant.     Time management: Meeting deadlines is crucial in software development. Strong time management skills enable developers to prioritize tasks effectively and deliver projects on time.     Attention to detail: Paying attention to details can help developers catch errors, bugs, and other issues before they become bigger problems.     Creativity: Creativity can help developers find innovative solutions to complex problems, and come up with new and better ways to approach development challenges.  These are just a few examples of soft skills that can be valuable in software development. Having a strong combination of technical and soft skills can help developers excel in their careers and contribute to successful software projects.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev  "
    }, {
    "id": 20,
    "url": "http://localhost:4000/post-random-tweet-on-twitter-api/",
    "title": "How to Post a Random Tweet using Twitter API",
    "body": "2022/12/07 - The Twitter API enables developers programmatically posting tweets. @Scheduled is a Spring annotation that marks a method to be scheduled. To execute @Scheduled annotations, we add an @EnableScheduling annotation on the main class. A cron job is a Linux job scheduler that sets up tasks periodically that run at a fixed date or interval. A cron attribute - as in Unix-based systems - enables the method to be executed at a specified date/time. 1@Scheduled(cron =  0 0 0/3 1/1 * ? )The requirement: We want to delegate our manual tweets to an automated process, even when we are sleeping, to support our social media automation. We have created a Tweet scheduling client to publish tweets under a Scheduler’s control. We have a text file listing all the articles we have written. 123456SOLID principles;article_URL;#solid #objectorientedBinary Search Tree;article_URL;#algorithm #datastructureClean code;article_URL;#programming #codingpractices. . . We have the following metadata for every article. 12345public class Article { String title; String link; String hashTags;}Load all the articles sequentially into a hashmap. We define the hashmap key as an integer to uniquely identify every article. 12345678910private Map&lt;Integer, Article&gt; articlesMap;. . . int n = 1;for (String line: allLines) { Article article = new Article(); //code omitted for brevity articlesMap. put(n++, article);}	 We choose a random number with the following method. 123private int getRandomNumber(int min, int max) { return ThreadLocalRandom. current(). nextInt(min, max + 1);}The following code snippet shows a method executed every three hours to retrieve a random article and send it to the Twitter API as a scheduled tweet. 123456789@Scheduled(cron =  0 0 0/3 1/1 * ? )public void postInTwitter() throws Exception { int n = getRandomNumber(1, articlesMap. size()); Article article = articlesMap. get(n); twitterService. sendPost(article);  logger. info( postInTwitter random article:   + article. getTitle());}But once an article is retrieved, the following article will probably be the same if we use the previous getRandomNumber method. Don’t post duplicate articles in a time frame. : What we want is to post no duplicate articles in a time frame. For example, if we post every three hours, eight posts are in one day. Well, we want to show eight no-duplicate tweets for our users throughout the day. As developers, we need to understand the inner workings of data structures to support the behavior - method - we want to implement. Could an array, linked list, queue, or stack satisfy our requirement? A Queue is an abstract data type, which includes a collection of objects that follow the first-in, first-out (FIFO) principle, i. e. , the element inserted at first is the first element to come out of the list. A MAX_ARTICLES variable defines your frame time. You can increase or decrease it according to the number of your articles. We define a queue of integers that is implemented by a linked list. 12private int MAX_ARTICLES = 8;private Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();Every three hours, we check if the new random number is not included in the queue. If the validation is successful, we retrieve a new article and publish it. The remove method deletes the oldest element from the queue (remember the element inserted at first is the first element to come out of the list). The new method executes (do) the following instructions while a new random number is not found. 123456789101112131415161718private Article getRandomArticle() { Article article = null; boolean newNumberFound = false; do {  int newNumber = getRandomNumber(1, articlesMap. size());  if (!queue. contains(newNumber)) {   newNumberFound = true;   article = articlesMap. get(newNumber);   if (queue. size() &lt; MAX_ARTICLES) {    queue. add(newNumber);   } else {    queue. remove();    queue. add(newNumber);   }  } } while (newNumberFound == false); return article;}The Big O notation to add and remove elements is O(1). This is how it looks at the new postInTwitter method. To evaluate the random behavior, we iterate the queue - only for test purposes. 12345678910@Scheduled(cron =  0 0 0/3 1/1 * ? )public void postInTwitter() throws Exception { Article article = getRandomArticle(); twitterService. sendPost(article); logger. info( postInTwitter random article:   + article. getTitle()); for (Integer item: queue) {  System. out. print(item +    ); } System. out. println();}Once you deploy the Tweet scheduling to any cloud provider, its log files show the queue’s random numbers, for example. 123456789101112131442 42 70 42 70 44 42 70 44 1 42 70 44 1 61 42 70 44 1 61 26 42 70 44 1 61 26 65 42 70 44 1 61 26 65 28 70 44 1 61 26 65 28 52 44 1 61 26 65 28 52 31 1 61 26 65 28 52 31 33 61 26 65 28 52 31 33 6 26 65 28 52 31 33 6 44 65 28 52 31 33 6 44 24 With the help of this Twitter bot, you can now focus on writing more articles. Look at it in action on my Twitter account!. Similar questions you can find in my book about algorithms and the inner workings of Data Structures. Learn how to apply common algorithms to practical problems. "
    }, {
    "id": 21,
    "url": "http://localhost:4000/assemble-parts-in-minimum.time/",
    "title": "Assemble Parts in Minimum Time",
    "body": "2022/11/12 - Write a method to calculate the minimum possible time to put the N parts together and build the final product. The input consists of two arguments: numOfParts, an integer representing the number of the parts, and parts, a list of integers representing the size of the parts. Example: numOfParts=4 parts=[8,4,6,12] Output: 58 Explanation: Step 1: Assemble the parts of sizes 4 and 6 (time required is 10). Then, the size of the remaining parts after merging: [8,10,12]. Step 2: Assemble the parts of sizes 8 and 10 (time required is 18). Then, the size of the remaining parts after merging: [18,12]. Step 3: Assemble the parts of sizes 18 and 12 (time required is 30). The total time required to assemble the parts is 10+18+30=58. 1234567public class AssembleParts { public static int minimumTime(int numOfParts, List&lt;Integer&gt; list) { //implement here your code  }}Solution: You can notice that we always take the first two parts of minimum size. Once we have its required time, the length of the list decreases by one element. Based on this behavior, we propose the following pseudocode to optimize the assembly process of parts to reduce the time it takes to complete the task.  Sorting a list in descending order.  Iterate the list Takes the first two parts and calculates the required time This required time creates a new element in the new list (decreased by one). Then overwrite the second index value with the “required time” calculated. This unique element will be the first part of the next iteration.  Accumulate the required time in every iteration. Before implementing your algorithm, create your assumptions based on test cases. 12345678910111213 @Test public void test_right_values() {  assertTrue(AssembleParts. minimumTime(4,      new ArrayList&lt;Integer&gt;(Arrays. asList(8, 4, 6, 12))) == 58);  assertTrue(AssembleParts. minimumTime(5,      new ArrayList&lt;Integer&gt;(Arrays. asList(3, 7, 2, 10, 5))) == 59); } @Test public void test_wrong_values() {  assertFalse(AssembleParts. minimumTime(3,      new ArrayList&lt;Integer&gt;(Arrays. asList(2, 4, 6))) == 12); }But what about the number of parts? You get the number of parts if you ask the size() method of the list. So in that case you never use the numOfParts argument. Validate your input data and check if the numOfParts value equals the list size. If you are facing a face-to-face interview, always ask the interviewer about the variables in case of doubt. Never assume and ask questions, this way you show that you will be a good team player in future projects. Our final algorithm for the Assembly optimization. 12345678910111213141516public class AssembleParts { public static int minimumTime(int numOfParts, List&lt;Integer&gt; list) {  if (numOfParts != list. size())   throw new RuntimeException( wrong number of parts );  Collections. sort(list);  int accumulatedTime = 0;  for (int idx = 0; idx &lt; list. size() - 1; idx++) {   int requiredTime = list. get(idx) + list. get(idx + 1);   accumulatedTime += requiredTime;   list. set(idx + 1, requiredTime);  }  return accumulatedTime; }}Similar questions you can find in my book about algorithms and data structures. Learn how to apply common algorithms to the practical problems.  "
    }, {
    "id": 22,
    "url": "http://localhost:4000/how-rest-client-handles-503-error/",
    "title": "REST client error handling - 503 Error",
    "body": "2022/11/04 - The HTTP 503 Service Unavailable server error response code indicates that the server is temporarily not ready to handle the request. Common causes of the 503 HTTP Status Code:  The server is down for a scheduled maintenance The server is overloaded due to too much trafficIn any case, the server will relieve itself after some delay. A REST client cannot control what happens on the server side: Business-to-business (B2B) is a typical scenario where one business acts as a client and the other acts as a server. A client-side company doesn’t care if there is a monolithic or microservice architecture on the server side.  We have implemented a web client that retrieves data from a thousand articles on each request. We need to send 50 thousand items. We reuse the following method to send a thousand articles every time. But suddenly, the external API throws an HTTP 503 status code. To avoid our REST client aborting the process, we catch the exception and put the error into a logger, and the program continues with the following one thousand articles. 123456789101112131415public Response getArticles(StringJoiner arrayOf1000Articles) throws Exception {   MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;&gt;(); map. add( content , arrayOf1000Articles. toString()); HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; request = new HttpEntity&lt;&gt;(map, headers); Response response = null; try {  response = new RestTemplate(). postForObject(URL_SERVER +  /articles/search , request, Response. class); } catch (Exception e) {  logger. error( Error in getArticles   + e. getMessage()); } return response; }Well, looking at our internal server logs - logger - won’t help to retry the request that failed. Sometimes we usually call the company that takes care of the external server. Usually, they report that there was a Service outage response. What this 503 error suggests is a retry action from our REST client to deal with external server errors. How does the REST Client automate a retry action?: As developers, we need to anticipate and automate retrying the request with a certain number of attempts. If the server error persists, we need to inform our users about the failed request’s content. The following code implementation handles 503 Service Unavailable Error. 12345678910111213141516171819202122232425public Response getArticles(StringJoiner arrayOf1000Articles) throws Exception {   MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;&gt;(); map. add( content , arrayOf1000Articles. toString()); HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; request = new HttpEntity&lt;&gt;(map, headers);  boolean success = false; int MAX_TRIALS = 3; int nextTrial = 1; Response response = null; do {  try {   response = new RestTemplate(). postForObject(URL_SERVER +  /articles/search , request, Response. class);   success = true;  } catch (Exception e) {   logger. error( Error in getArticles   + e. getMessage());   nextTrial++;  } } while (!success &amp;&amp; nextTrial &lt;= MAX_TRIALS);  if (!success)  informError( Error in getArticles   + arrayOf1000Articles. toString());  return response; }For simplicity and learning purposes, we assume we receive an HTTP status code of 503 within the try &amp; catch block. You can simulate a HTTP status code 503 by calling the httpstat. us service. Call the service httpstat. us with the desired response code in the URL path. 1$ curl -v http://httpstat. us/503The response looks like this: 1234567&gt; GET /503 HTTP/1. 1&gt; Host: httpstat. us&gt; User-Agent: curl/7. 54. 0&gt; Accept: */*&gt;&lt; HTTP/1. 1 503 Service Unavailable. . . Understand the basics of common data structures and algorithms and apply them to real questions.  "
    }, {
    "id": 23,
    "url": "http://localhost:4000/load-balancing-clustering/",
    "title": "File Access Denied in a Cluster with Load Balancing",
    "body": "2022/10/05 - Load balancing is a process that routes network traffic to a group of backend servers, also known as a server pool. A load balancer is responsible for distributing incoming requests to a collection of application servers. Load balancers help solve problems of server performance, high availability and scalability in distributed systems. Application Server: Application server refers to the process that provides the functions required to support and host user applications. For example, in Websphere, an application server runs Java language-based applications. Clustering: A cluster is a group of servers that are managed together. For example, in the WebSphere Application Server, all application servers processes are running the same set of enterprise applications, and the workload capacity is distributed between these servers.  The benefits of building a cluster are:    Scalability enables enterprise applications to handle an increase in load volumes properly and achieve better throughput by using more infrastructure resources.     High availability means enterprise applications can continue to process work and avoid impacts in the occurrence of failure of one or several components.  When a Cluster shares a File Server: We want to deploy a Java WebClient to retrieve image objects from an external API and store it in an internal file server. The Java WebClient is deployed in a cluster with two application servers.  The cluster uses a load balancer to delegate a specific task to one of its servers in a randomized order. A load-balancing algorithm is a load balancer’s logic to distribute network traffic between servers. The first time a user requests the execution of the Java WebClient, the load balancer delegates the task to the first application server, for example. The Java WebClient stores some image files in a directory, and the AppServer1 server owns those files. 12U:\imagesFromApi\image1. jpg (owner AppServer1)U:\imagesFromApi\image2. jpg (owner AppServer1)One week after, the Java WebClient is requested again, but it needs to execute the following code to delete an image file on the internal file server if the same image was deleted on the external API. 12345678public void deleteFile(String fileName) throws Exception { try {  File file = new File(OUTPUT_FILE_LOCATION + fileName);  file. delete();  } catch (Exception e) {  logger. error( Exception in deleteFile   + e. getMessage()); }}But this second time, the load balancer delegates the execution of the task to the second application server - AppServer2. Then, the java client throws an error. 1Access is deniedThe Java WebClient cannot delete files that another user created. We cannot change the permissions of a file from within a Java program as we can on Linux systems - chmod command. Possible Solutions:  Configure only one user account on application servers and give it full access control - hardware configuration.  Deploy the Java WebClient in only one server. Now any application server in the cluster can create or delete any file on the file server. "
    }, {
    "id": 24,
    "url": "http://localhost:4000/german-vocabulary-software-engineers/",
    "title": "German vocabulary for Software Engineers",
    "body": "2022/10/03 - A helpful vocabulary with the most common words when working as a software developer in Germany. I have worked in Berlin for eight años and would like to share this vocabulary with the most common words used in my software meetings, documents, emails, and coding tasks. As part of my continuous german learning, I will update the list occasionally. Softwareentwicklung : software development: die Anwendung : application die Anforderung : requirement die Bereitstellung : deployment das Betriebssystem : operating system der Codierer : coder erstellen : create die Erstellung : creation die Entwicklung : development die Gestaltung : design Internet der Dinge (IoT) : Internet of Things IT-Lösung : IT-solution das Konzept: plan. It is a document that describes a plan to carry out a project. Loop-Anweisung : LOOP statement der Programmierer : programmer Programmiersprache : programming language die Qualitätssicherung : quality assurance die Softwarearchitektur : software architecture der Softwareentwickler : software developer der Softwareentwurf : software design die Umgebung : environment die Umsetzung : implementation die Unterstützung : support Anwendungen : Applications: abbrechen : cancel aktualisieren : update Allgemeine Eigenschaften : general properties analysieren : analyze die Anfrage : request die Angabe (Daten) : information, data anlegen (Datei) : create annehmen : accept anpassen : customize, adapt anwenden : apply der Anwender (von Software, Programmen) : user Ausnahmebehandlung : exception handling der Aufruf : call aufrufen (Programm, Datei) : invoke der Ausdruck : printout der Ausfall : outage ausliefern : deploy der Bericht : report die Betriebsbereitschaft : readiness for service (or operation) die Datei : file (computer) Datei entfernen : remove file die Datenlast : data load deinstallieren : uninstall durchsuchen : browse die Einstellungen : settings eingeben (Daten) : enter X durch Y ersetzen : replace X by Y entfernen: remove exportieren : export der Fehler : error Fehler (Programmierfehler) : bug fertigstellen (Installation) : finish herunterladen : download hinzufügen : add hochladen (Daten, Programm) : upload Implementierungseinstellungen : deployment settings installieren : install Künstliche Intelligenz : Artificial intelligence löschen : delete das Quellcode : source code die Schnittstelle : interface starten : start stoppen : stop Unternehmensanwendung : Enterprise Application verlassen (Programm) : quit verwenden : use die Voraussetzung : prerequisite, (pre)condition weiter : next züruck : previous zurücksetzen : reset Am Computer: der Bildschirm : screen der Drucker : printer einrichten : set up die Festplatte : hard disk HD das Gerät : device das Kabel : cable der Lautsprecher : speaker die Maus : mouse der Monitor : monitor die Tastatur : keyboard die Taste : key Sicherheit : Security: absichern : secure, protect Authentifizierung : Authentication dir Autorisierung : authorization beschränken : limit, restrict die Bedrohung : threat das Benutzerkonto : user account der Cyberangriff : cyber attack der Datenschutz : data protection datenübernahme : data transfer erzeugen (Token) : generate fehlerhaft : bad, corrupted freischalten : authorize das Kennwort : password der Identitätsdiebstahl : identity theft passwordgeschützt : password protected setzen (Prioritäten) : set die Sicherheit : security Sicherheitsprüfung : security auditing der Schlüssel : cipher key to secret code die Sitzung : session die Verschlüsselung : encryption Verwaltungssicherheit : Administrative security Verwaltung von SSL-Zertifikaten und Schlüsseln : SSL certificate and key management Zertifikatsverfall : certificate expiration der Zugriff : access der Zugriffscode : access code Datenbank : Database: abbilden : represent, depict die Abfrage : query das Austauschformat : interchange format der Datenaustausch : data exchange Stammdaten : master data die Textdatei : text file der JDBC-Treiber : JDBC driver zuordnen : allocate Networking: dir Glasfaser : optical fiber herstellen : establish die Verknüpfung : link die Verbindung : connection "
    }, {
    "id": 25,
    "url": "http://localhost:4000/the-ubiquitous-language/",
    "title": "How to establish an effective ubiquitous language in domain-driven design",
    "body": "2022/08/27 - A Domain is an area of knowledge associated with a problem we are trying to solve. A Domain Model represents those aspects of a domain that are relevant to a particular problem. Domain Driven Design aims to build strategic software based on domain models and defines two fundamental concepts to achieve it.    Bounded Context is a subsystem that defines a specific responsibility with an explicit boundary. For example, in a shopping application, we build specific components to support the Sales Context and others to support the Buyer Context.     The Ubiquitous Language reflects a language spoken among team members working in the Bounded Context.  Using bounded contexts reduces coupling between subsystems, and we can exchange data between them via explicit API, avoiding dependencies. As developers, we must choose appropriate names for our variables that reflect the business terms used in all communication channels during the Domain modeling design stage.  Case study: Business-to-business (B2B) is a business conducted between one company and another. A leading company implements an e-commerce portal to sell t-shirt products from various vendors and manufacturers. A vendor wants to avoid duplication of effort to manually upload images on both sides and asks the lead company to use an internal API to update their product images. During the integration process, business experts and developers are in constant communication to clarify requirements. For example.  The vendor communicates to the development team that its internal API describes a mediaAssetID attribute to uniquely identify an image object in its domain.  Email interactions occur to clarify how to build a URL path to retrieve the final image object using the mediaAssetID attribute. We want to introduce business terminology into our variable names Understand business concepts before translating them into source code: The ubiquitous language is the language of the business. Technical names are not allowed to describe the business domain. Ubiquitous language in software development is a set of concepts and vocabulary shared between everyone on the team. Some developers can specify the following class design when your bounded context is translated into source code. 1234567public class Product { private int id; private String imageId; private String imageURL;  //code omitted for brevity}The imageId attribute is a good name, but other business domains may already use it. We, as developers, sometimes disconnect from business and look for variable names that usually follow conventions, standards, programming languages, framework recommendations, or technical terms. If we’ve been involved in requirements analysis for weeks, why not introduce the same business terminology into our variable names? Variable names reveal intent. One of the benefits of using ubiquitous language is introducing the influence of business communication structures on software. Whenever you can, try to introduce business terminology into your variable names. By introducing a better name for our variables, we can establish an effective ubiquitous language in domain-driven design 1234567public class Product { private int id; private String mediaAssetID; private String mediaAssetURL;  //code omitted for brevity}Never assume and ask questions to clarify ambiguous and synonyms terms: You receive a task to implement a service to retrieve documents used in the shipment of goods, and you decide to call it shipping notes. But your business doesn’t ship goods by the sea! Ask always questions to your colleagues and domains experts to clarify business concepts. Then you will realize that your service should implement delivery notes. The following class design represents a fundamental concept in the domain expert’s mental model. 1234public interface DeliveryNoteService { //code omitted for brevity}Use the ubiquitous language as a tool for effective cross-team collaboration and knowledge sharing. Using the Ubiquitous language in agile software development and in domain modeling of microservices architecture is a common practice.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 26,
    "url": "http://localhost:4000/understanding-oop-concepts/",
    "title": "Understanding OOP concepts",
    "body": "2022/05/20 - Understanding OOP concepts give you a solid foundation for making critical decisions about object-oriented software design. Class: A class is a template or prototype that describes what an object will be. It defines its attributes(data) and behavior(methods). We must design a class before creating an object. Object: An object is an instance of a class. When we create an object, we create real-world entities such as cars, bicycles, or dogs with their own attributes and own behaviors.  We instantiate an object via the new keyword in the Java programming language. When you design a class follow the Single Responsibility Principle (SRP). Abstraction in OOP: Abstraction allows an object telling to its users what an application does instead of how it does it. You can see the essential buttons on your TV remote control, but you don’t care what happens behind when you press one of these buttons. In Java, we create abstractions via Interfaces and Abstract classes. Encapsulation in OOP and Data Hiding: Restricting access to specific attributes and methods is called data hiding. Objects should not manipulate the data of other objects. Encapsulation is the action of combining the data and methods in the same entity. In this way, we control access to the data in the object. Inheritance in OOP: Inheritance is a process in which a class inherits the attributes and methods of another class. Class inheritance in OOP provides the ability to create new classes with new functionalities while maintaining the functionalities inherited. In this way, it promotes code reusability. This relationship is an is-a relationship because when a subclass inherits from a superclass, it can do anything that the superclass can do. In Java, we create inheritance between classes via the extends keyword. Polymorphism in OOP: Polymorphism in OOP means many shapes and is coupled to inheritance. For example, a Shape class defines a draw method, but Square and Circle’s subclasses will implement it differently. Composition in OOP: The composition in OOP provides a mechanism for building classes from other classes. In Java, we usually create a class with instance variables that references one or more objects of other classes. The benefit of separating one class from another one is the Reuse. For example, in a shopping context, we need a list of requested items and an address where to deliver the order. 12345678public class Order { private int clientId; private List&lt;Item&gt; orderItems; private Address shippingAddress;  //code omitted for brevity}We build an Item class including an Article class. 1234567public class Item { private Article article; private double quantity;  //code omitted for brevity}And the Article class includes enough attributes to support the shopping business. 12345678public class Article { private int id; private String name; private double deliveryPrice;  //code omitted for brevity}Even we can reuse the Article class to support a Search request. 123456public class SearchResponse { private List&lt;Article&gt; articles;  //code omitted for brevity} What happens if the business wants to introduce articles in a country where some articles are forbidden to trade?. We can not add a new attribute called tradable to the Article class because we will never use it in normal countries. Here, we can use the other technique to build new classes: inheritance.  Now, we can support the new requirement for the new country. 123456public class SearchResponse { private List&lt;TradableArticle&gt; articles;  //code omitted for brevity}We can reuse our classes even out of context. For example, in a Bank context, we need an address to contact a customer. 12345678public class Customer { private int customerId; private String lastName; private Address address;  //code omitted for brevity}We use the term has-a to describe composition relationships. An order has-a(n) address. A customer has-a(n) address. Advantages of object-oriented programming:  Your program focuses on data, not on functions. You create a program using objects, not functions.  You define methods to control the access to its data.  Objects communicate through methods - messages The application adapts to new changes.  Objects have unique responsibilities.  You don’t define global data. Every object contains its data. Understanding OOP concepts in Java or Python OOP concepts makes your system design resilient to future changes. Learn how to use these concepts in SOLID design principles.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 27,
    "url": "http://localhost:4000/ssl-handshake-failure/",
    "title": "Resolving SSL handshake failure in Java applications",
    "body": "2022/05/11 - The Secure Socket Layer (SSL) enables a secured connection between a client and a server. SSL Handshake is a set of steps that make it possible for this secured connection over the network. A summary of the steps in the SSL handshake:  Agree on the version of the cryptographic protocol to use.  Select cryptographic algorithms - cipher suites to use.  Exchange and validate digital certificates to authenticate each other.  Generate a shared secret key using asymmetric encryption techniques. For more information about cryptographic algorithms and digital certificates, refer here. SSL handshake failure during API integration: We try to build a Spring WebClient component to consume data from an API Server (target_server). Requisites:  SDK: 1. 8 java version “1. 8. 0_191” Websphere application server123456789101112131415String username= here_username_target_server ;String password =  here_password_target_server ;WebClient webClient = WebClient. builder() . baseUrl( baseUrl_target_server ) . filter(basicAuthentication(username, password)) . build();Mono&lt;String&gt; monoString = webClient . get() . uri( uri_target_server ). accept(MediaType. TEXT_PLAIN) . retrieve() . bodyToMono(String. class). log();logger. info(monoString. block());Once the client is running, it throws the following error - a common SSL Handshake issue. 1ERROR WebClientRequestException: Received fatal alert: handshake_failure; nested exception is javax. net. ssl. SSLException: Received fatal alert: handshake_failure)What is TLS?: Transport Layer Security (TLS) is a protocol for implementing cryptography on the web. Encrypts data sent over the Internet to ensure hackers cannot see your sensitive information such as passwords or credit card numbers. TLS protocol evolved from Secure Socket Layer (SSL) developed by Netscape to secure web sessions. Cipher Suite: A Cipher Suite is a set of cryptographic algorithms used by an SSL or TLS connection. A suite includes three distinct algorithms:  The key exchange and authentication algorithm.  The encryption algorithm to encipher the data The MAC (Message Authentication Code) algorithm generates the message digest. For example, the Cipher Suite SSL_RSA_WITH_RC4_128_MD5 includes:  The RSA key exchange and authentication algorithm The RC4 encryption algorithm, using a 128-bit key The MD5 MAC algorithm How to interpret SSL handshake failure logs: We usually check if both parties - client and server - comply with all the steps of the SSL Handshake mechanism. The first two steps deal with cryptographic protocols and cipher suites. Returning to our scenario, when the client initializes, we see the following lines on the console. 123415:11:23. 567 [main] DEBUG io. netty. handler. ssl. OpenSsl - netty-tcnative not in the classpath; OpenSslEngine will be unavailable. 15:11:24. 939 [main] DEBUG io. netty. handler. ssl. JdkSslContext - Default protocols (JDK): [TLSv1]15:11:24. 939 [main] DEBUG io. netty. handler. ssl. JdkSslContext - Default cipher suites (JDK): [TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA]We can realize Client is using the TLSv1 protocol Now let’s see on the server-side by using an OpenSSL command. (On Windows PC we can use Git Bash) 1openssl s_client -connect &lt;IP&gt;:&lt;PORT&gt;Now, we can see the response. 12345678910111213---SSL handshake has read 5388 bytes and written 473 bytesVerification: OK---New, TLSv1. 2, Cipher is ECDHE-RSA-AES128-GCM-SHA256Server public key is 4096 bitSecure Renegotiation IS supportedCompression: NONEExpansion: NONENo ALPN negotiatedSSL-Session:  Protocol : TLSv1. 2  Cipher  : ECDHE-RSA-AES128-GCM-SHA256The server uses the TLSv1. 2 protocol, which means the Client and Server are not using the same protocol version. Fixing SSL handshake failures: From the server response, some ciphers are not supported in the TLSv1. 2 protocol. We can upgrade the java version, but sometimes it is not easy because many applications depend on WebSphere licenses, and we need to wait until the next release. Once we have identified the supported Protocol and Cipher Suites supported by the server, we can modify the ones supported by the Client through the TLS configuration to be able to connect to the Server. Or we can implement the following system property to our Client code. 1System. setProperty( com. ibm. jsse2. overrideDefaultTLS , true );We rerun the Client and see the console. 123416:32:56. 858 [main] DEBUG io. netty. handler. ssl. OpenSsl - netty-tcnative not in the classpath; OpenSslEngine will be unavailable. 16:32:58. 106 [main] DEBUG io. netty. handler. ssl. JdkSslContext - Default protocols (JDK): [TLSv1. 2, TLSv1. 1, TLSv1]16:32:58. 106 [main] DEBUG io. netty. handler. ssl. JdkSslContext - Default cipher suites (JDK): [TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA]Now Client and Server are agreed on the SSL Handshake and can exchange data. "
    }, {
    "id": 28,
    "url": "http://localhost:4000/spring-boot-oauth2/",
    "title": "Spring Boot, OpenAPI3, and OAuth2",
    "body": "2022/04/26 - This tutorial will show how to integrate OAuth2 with Spring Security in a Spring Boot application with OpenAPI 3. The Spring Boot application I am going to use is based on my previous article: Documenting a SpringBoot REST API with OpenAPI 3 OAuth: OAuth is an authorization framework many companies use to secure access to their protected resources. It performs this by using access tokens. The token represents a delegated right of access on behalf of the resource owner. Roles: OAuth defines four roles    The Resource Owner is the user who grants access to a protected resource.     Resource Server stores users’ data and HTTP services and responds to protected resource requests using access tokens.     The client is the application that requires access to protected resources on behalf of the resource owner and its authorization.     The authorization server is responsible for authenticating the user’s identity and giving an authorization token.  Authorization grant: An authorization grant is a credential representing the resource owner’s authorization used by the client to obtain an access token. OAuth2 defines four grant types.    Authorization Code, for web apps that are server-side apps     Implicit, optimized for clients implemented in a browser using a scripting language such as JavaScript     Resource Owner Password Credentials are used when there is a high degree of trust between the resource owner and the client     Client Credentials are used when the client is requesting access to protected resources based on an authorization previously arranged with the authorization server.  The Client Credentials grant type is the most appropriate for server-to-server applications, such as typical B2B interactions. Getting Started: To integrate OAuth2 in a Spring Boot application, we add the Spring Oauth dependency to our pom. xml file. 12345&lt;dependency&gt; &lt;groupId&gt;org. springframework. security. oauth. boot&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2. 5. 1&lt;/version&gt;&lt;/dependency&gt;Enable Authorization Server Support: We open the main application class and add @EnableAuthorizationServer to enable the support for the authorization server. 1234567@EnableAuthorizationServer@SpringBootApplicationpublic class OpenapiApplication {	public static void main(String[] args) {		SpringApplication. run(OpenapiApplication. class, args);	}}@EnableAuthorizationServer enables the client credentials grant type by default. Creating ClientId and Client Secret: Open/create the resources/application. yml file and add the following properties: 12345678security: oauth2:  client:   client-id: codercuy-client   client-secret: strong-secret   scope:    - read    - writeWe need to tell Spring which endpoints -resources- must be authenticated. Otherwise, all requests will skip security. Enable Resource Server Support: Create a class that extends ResourceServerConfigurerAdapter and add the following code. 123456789101112@Configuration@EnableResourceServerpublic class OAuth2ResourceServer extends ResourceServerConfigurerAdapter{ @Override public void configure(HttpSecurity http) throws Exception {  http      . authorizeRequests()      . antMatchers( /api/** ). authenticated()      . antMatchers( / ). permitAll(); }}Now, run the main application. http://localhost:8080/swagger-ui. html And try to insert a book (Try out button). In the bookAuthorization parameter, write anything (“key,” for example). Then you receive an error.  Why does this happen? Well, we need to tell OpenAPI that configures security. Configure OpenAPI and Oauth2: To integrate OpenAPI 3 with OAuth2, open the OpenApiConfig class and add the new code. 123456789101112131415161718192021222324252627282930@Configurationpublic class OpenApiConfig { @Bean public OpenAPI customOpenAPI() {  return new OpenAPI()    . components(new Components()        . addSecuritySchemes( spring_oauth , new SecurityScheme()            . type(SecurityScheme. Type. OAUTH2)            . description( Oauth2 flow )            . flows(new OAuthFlows()                . clientCredentials(new OAuthFlow()                    . tokenUrl( http://localhost:8080  +  /oauth/token )                    . scopes(new Scopes()                        . addString( read ,  for read operations )                        . addString( write ,  for write operations )                    ))))    )      . security(Arrays. asList(          new SecurityRequirement(). addList( spring_oauth )))    . info(new Info()      . title( Book Application API )      . description( This is a sample Spring Boot RESTful service using springdoc-openapi and OpenAPI 3.  )      . termsOfService( terms )      . contact(new Contact(). email( codersitedev@gmail. com ). name( Developer: Moises Gamio ))      . license(new License(). name( GNU ))      . version( 2. 0 )    ); }} From the previous code, you can see that before setting up a security requirement in OpenAPI, we need to define a new security scheme component called “spring_oauth” for example. Now, rerun the main application, and we can see a new green button called Authorize. Then enter the credentials and the scope.  Close the pop-up and try out again to insert a book.  Yes, you did it! Now, your endpoints are secured and protected with OAuth2. Please donate to maintain and improve this website if you find this content valuable.   "
    }, {
    "id": 29,
    "url": "http://localhost:4000/uml-diagrams-for-java-developers/",
    "title": "UML Diagrams for Java Developers",
    "body": "2022/03/09 - The Unified Modeling Language is a graphical notation for modeling systems and conveying User software requirements. All developers must understand this notation before starting programming. UML is not only pretty pictures. Instead, they communicate the software design decisions to programmers. Use case: As entrepreneurs, we usually pay for costly advertisements to promote our products. We can create a little application to make our ads, promote them as printed flyers, and reduce our investments in ads. Every developer can abstract the main components from a user requirement differently. Having a standard UML notation helps to eliminate ambiguities about the requirements from the beginning. I want to show you how to translate business requirements into technical solutions with this use case. User requirement: Given a text message, a URL link, and an image, build a service that automates the composition of flyer design, including the image, text, and the QR code for the link in a PDF file with an A4 format divided into one, two, four or eight parts ready to print.  From the user requirement, we can realize that we need a task to create a QR code, a job to manipulate elements inside an image, and a task to create a PDF file. We can implement our code or reuse external libraries as dependencies, but the following figure shows the desired result, whatever the implementation approach is chosen.  Why do we model?:  We build models to understand better the system we are developing.  Models document the design decisions we have made.  Models allow an open discussion in the development team before starting programming.  It speeds up the implementation stage because potential technical issues are discussed during the design stage. Visualizing software architecture - design proposal: The C4 model enables software development teams to describe and communicate software design decisions, similar to Google maps zooming in and out of an area of interest. These areas of interest in the software are: Context -&gt; Containers -&gt; Components -&gt; Code - UML Notation  Context diagram: A system context diagram shows the big picture. This diagram shows actors and software systems rather than technologies. For our use case, it says that building a new web application will achieve the user requirement.  Container diagram: The container diagram shows how the responsibilities are distributed in different execution units - containers. We need a Form on the front end and an API application on the back end for our web application.  Component diagram: As system analysts, we delegate responsibilities to software elements called components or services that execute sub-tasks with specific technologies to achieve the user software requirements. Read the Single Responsibility Principle. The API application interacts with the user requests. Then, delegates the following subtasks to different services.  Generate a QR Code based on the URL link achieved by the QR Service.  Merge the previous QR Code, text message, and image in a final image design performed by the Image Service.  Build a PDF file that includes the last design image achieved by the PDF Service. The API application returns the final image design in a PDF file to the user.  It’s better to include a new service called FlyerComposerService between the API application and the three services. It facilitates the migration task if you want to adopt a microservices architecture. The FlyerComposerService class is responsible for orchestrating all calls to these three last services. UML Class Diagrams: A class is a template for creating objects providing initial values for state (attributes) and behavior (operations). Each attribute has a type. Each operation has a signature.  From the figure above:  The first compartment describes the class name.  The second compartment describes the attributes with its visibility, private(-) or public(+), and their types.  The third compartment describes the operations and their return types. The following code snippet shows how these compartments are translated into code. 123456789101112131415public class FlyerComposerService { private QRService qrService; private ImageService imageService; private PDFService pdfService;  public byte[] composeFlyer(String[] qrText,  String text,  byte[] image,  int nroFlyers) {    //code omitted for brevity }}Relationships between classes: UML conveys how a class is related to other classes. Let’s see the kind of relationships that matter to our design. Dependency: Dependency is a relationship used to show that some class requires or depends on another class or interface. In other words, some class provides (supplier) particular functionalities that others require (client). At the FlyerComposerService class above, we can see how is declared the dependencies as member variables. Realization: Realization is a relationship where one class realizes or implements the specification defined in another class (usually an interface). Defining and creating interfaces is an excellent approach to building software to is extendable. Read the Open-Closed Principle. The implemented code reflects the intent of the UML designer. : Using UML diagrams in Java projects is an excellent tool for effective team communication. The following figure conveys the Class diagram.  For example, we can see how the QRService interface is implemented into code. 123public interface QRService { byte[] generateQRCode(String qrText) throws Exception;}In addition, we can see how the QRServiceImpl class is implemented into code 1234567public class QRServiceImpl implements QRService { @Override public byte[] generateQRCode(String qrText) throws Exception {  //code omitted for brevity }}Conclusions:  UML convey how to build the software without ambiguities, e. g. , build first an interface instead of a class.  Modeling through UML yields an understanding of a system.  An explicit UML class diagram facilitates communication between developers.  UML diagrams can be used as a documentation tool for Java development teams. We will see how to implement every Spring Boot service in the following articles, so follow me! Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 30,
    "url": "http://localhost:4000/open-closed-principle/",
    "title": "SOLID principles: The Open-Closed Principle (Part II)",
    "body": "2022/01/06 - SOLID principles tell you how to arrange your functions into classes and how those classes should be interrelated. When SOLID principles are applied correctly, your software infrastructure will be able to tolerate changes, it will be easier to understand, and it will be focuser on reusable components. After looking at the Single Responsibility Principle, let’s continue with the second principle. SOLID principles: The Open-Closed Principle (OCP):  … “a module, class, or function should be open for extension but closed for modification. “ Bertrand Meyer coined the principle, suggesting that we should build software to be extendable without touching its current code implementation. But there are situations we change one of our classes, and we realize that we need to adapt all its depending classes. Explaining the Open-Closed Principle with code examples: For instance, imagine designing and implementing a rate limit algorithm to control the number of requests allowed for every endpoint in a REST API. The RateLimit class implements an interceptor - HandlerInterceptor - that allows an application to intercept HTTP requests before they reach the service, so we can either let the request go through or block it and send back the status code 429. 12345678910111213public class RateLimit implements HandlerInterceptor { private Map&lt;String, Long&gt; apiPlans;  @Override public boolean preHandle(HttpServletRequest request,   HttpServletResponse response, Object handler) throws Exception {  //getClientId  apiPlans = getAPIPlans();  //build Buckets  //evaluate request per clientId  //accept(200) or refuse(429) request }}The number of requests allowed during a time interval is specified in plans; for example, plan A allows to consume 100 requests in 1 minute. The team wants to retrieve the number of requests by plan from a text file. The following getAPIPlans method retrieves those parameters. The following getAPIPlans method retrieves those parameters. 12345678910111213141516private Map&lt;String, Long&gt; getAPIPlans() throws Exception { Map&lt;String, Long&gt; apiPlans = new ConcurrentHashMap&lt;&gt;(); Resource resource = new ClassPathResource( apiPlans. txt ); try {  List&lt;String&gt; allLines = Files. readAllLines(Paths. get(resource. getURI()));  for (String line: allLines) {   String[] attributes = line. split( : );   String plan = attributes[0];   long capacity = Long. valueOf(attributes[1]). longValue();   apiPlans. put(plan, capacity);  } } catch (IOException e) {   throw new RuntimeException(e. getMessage()); } return apiPlans;}When suddenly, an unexpected scenario arises: The developer leaves the company, and a new one arrives—for example, You. As developers, we usually receive tasks to do maintenance in projects that do not belong to us; specifically, we never created that code. Then weeks later, your team decides that must be retrieved parameters from a database. Therefore you proceed to replace the getAPIPlans method; then, you break the open-closed principle. That is the meaning of the principle; you can not touch the code that is already implemented and working for a long time. Suppose the code is too complex to understand, not well documented, and includes a lot of dependencies. In that case, we have a lot of probabilities to introduce a bug or break some functionalities that we cannot visualize. Unless it is a bug that we have to fix, we should never modify the existing code. Even if the code is not well designed or does not follow well object-oriented principles, it could not be easy to extend a class to introduce new functionalities. The team wants to implement the open-closed principle to support future changes for this scenario. But they need to adopt Refactoring techniques to promote the Open-Closed Principle. For this scenario: polymorphism and aggregation. Polymorphism: Polymorphism is part of the core concepts of Object-Oriented Programming and means many forms, allowing an object to behave differently in some instances. For our scenario, polymorphism will enable the getAPIPlans method to achieve its goals in different ways: retrieve the parameters from a text file or a database. Aggregation: Aggregation defines a HAS-A relationship between two classes. Their objects have their life cycle, but one of them is the owner of the HAS-A relationship. The following diagram shows the goal of our design.  Read more about Object-Oriented Programming concepts Achieving extensibility with the Open-Closed Principle: Firstly, and thinking abstractly, you should create an interface and define a contract that will include all required functionalities. 12345public interface DataService { public Map&lt;String, Long&gt; getAPIPlans() throws Exception;}Secondly, we move our getAPIPlans method to a new class that implements the previous interface. 123456789public class TextData implements DataService { @Override public Map&lt;String, Long&gt; getAPIPlans() throws Exception {  Map&lt;String, Long&gt; apiPlans = new ConcurrentHashMap&lt;&gt;();  //code omitted for brevity	  return apiPlans; }}Thanks to abstractions, we can create a new class to implement getAPIPlans with different behavior, in this case, to retrieve parameters from a database. 1234567891011121314151617public class DBData implements DataService { private DataSource datasource;  public DBData(DataSource datasource) {  this. datasource = datasource; }  @Override public Map&lt;String, Long&gt; getAPIPlans() throws Exception {  Map&lt;String, Long&gt; apiPlans = new ConcurrentHashMap&lt;&gt;();  for (Plan plan : datasource. getAPIPlans()) {  //code omitted for brevity	   }  return apiPlans; }}Introducing a new abstraction layer with different implementations avoids tight coupling between classes. Finally, we refactor our RateLimit class aggregating an instance of DataService type in its constructor method. 123456789101112131415161718public class RateLimit implements HandlerInterceptor { private Map&lt;String, Long&gt; apiPlans; private DataService dataService;  public RateLimit(DataService dataService) {  this. dataService = dataService; }  @Override public boolean preHandle(HttpServletRequest request,   HttpServletResponse response, Object handler) throws Exception {  //getClientId  apiPlans = dataService. getAPIPlans();  //build Buckets  //evaluate request per clientId  //accept(200) or refuse(429) request }}If later we decided to retrieve the parameters from a NoSQL database, we would no longer have to touch the code, create a new class that implements getAPIPlans, and instantiate this new class in RateLimit. Even if, instead of implementing the HandlerInterceptor interface, we implement a Filter to design our Rate Limit algorithm, we can reuse the DataService interface as one of its dependencies. Calling to getAPIPlans is now fixed (closed for modification). If we want it to behave differently, we implement it in a new class (open for extension) that will follow the contracts defined in our interface. Our new DBData dependency is instantiated in our RateLimit class thanks to the magic of the Dependency Injection principle, which I will explain in a near-future article, so follow me!. Applying these Refactoring techniques, the Open-Closed Principle enhances software maintainability. Do you want to know more about software design Principles? Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 31,
    "url": "http://localhost:4000/merge-two-sorted-lists/",
    "title": "Merge two sorted lists algorithm",
    "body": "2021/08/04 - A merging algorithm takes two sorted lists as input and produces a single list as output, containing all the elements of the two inputs lists in sorted order. A List is an abstract data type that can store a list of items. Unlike traditional arrays, however, lists can be expanded and shrunk and are stored dynamically in memory. Problem: Given two sorted lists, merge them in a new sorted list.  Solution: We can join the two lists into a new list and apply a sort algorithm such as bubble sort, insertion, or quicksort. What we are going to do is to implement a new algorithm with a NlogN performance.  We define a new List to add all elements from the other two lists in a sorted way.  We define two indexes that point to every element in every list We iterate both lists while still exist elements in both lists We compare elements from both lists and add the smaller one to the new list in every iteration. Before passing to the next iteration, we increment in one the index of the list, which contains the smaller element.  If there is a list that still contains elements, we add them directly to the new list. A test case helps to validate your assumptions: Our assumption based on a test case: 123456789101112131415@Testpublic void mergeSortedLists() { List&lt;Integer&gt; sList1 = Arrays. asList(1,1,2,5,8); List&lt;Integer&gt; sList2 = Arrays. asList(3,4,6); assertEquals( [1, 1, 2, 3, 4, 5, 6, 8] ,    SortedList. merge_sorted(sList1,sList2). toString());}@Testpublic void mergeSortedLists2() { List&lt;Integer&gt; sList1 = Arrays. asList(2,4,5); List&lt;Integer&gt; sList2 = Arrays. asList(1,3,6); assertEquals( [1, 2, 3, 4, 5, 6] ,   SortedList. merge_sorted(sList1,sList2). toString());}Merging sorted lists in a single pass: Here, the implementation code: 123456789101112131415161718192021public class SortedList { public static List&lt;Integer&gt; merge_sorted(  List&lt;Integer&gt; sList1, List&lt;Integer&gt; sList2) {  List&lt;Integer&gt; mergedSortedList = new ArrayList&lt;&gt;();  int idx1 = 0;  int idx2 = 0;  while (idx1 &lt; sList1. size() &amp;&amp; idx2 &lt; sList2. size()) {   if (sList1. get(idx1) &lt;= sList2. get(idx2)) {    mergedSortedList. add(sList1. get(idx1));    idx1++;   } else {    mergedSortedList. add(sList2. get(idx2));    idx2++;   }  }  return mergedSortedList; }}The previous algorithm is missing how to proceed when one of the lists still contains elements not compared. Keep reading here "
    }, {
    "id": 32,
    "url": "http://localhost:4000/hot-warm-architecture-elasticsearch/",
    "title": "Implementing hot-warm architecture in Elasticsearch for time-series data",
    "body": "2021/02/26 - Elasticsearch is a distributed real-time document store where every field is indexed and searchable. It provides near real-time search and analysis for all types of data. Elasticsearch is document oriented, meaning that it stores entire objects or documents. Fundamentals concepts: The act of storing data in Elasticsearch is called indexing. An index is a collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data. Every index has some properties like mappings, settings, and aliases. In Elasticsearch, a document belongs to a type, and those types live inside an index. We can draw a parallel to a traditional relational database: Relational DB ⇒ Databases ⇒ Tables ⇒ Rows ⇒ Columns Elasticsearch ⇒ Indices ⇒ Types ⇒ Documents ⇒ Fields In Elasticsearch, the term document has a specific meaning. It refers to the top-level, or root object that is serialized into JSON and stored in Elasticsearch under a unique ID. Elasticsearch lets you insert documents without a predefined schema (in RDBMS you need to define tables in advance). Inverted index Relational databases add an index, such as a B-tree index, to specific columns in order to improve the speed of data retrieval. Elasticsearch use a structure called an inverted index for exactly the same purpose. By default, every field in a document is indexed (has an inverted index) and thus is searchable – FullText search. A field without an inverted index is not searchable. An inverted index consists of a list of all the unique words that appear in any document, and for each word, a list of the documents in which it appears For example, your billing and ordering applications print the following message to the log file of their respective application servers. 1[11. 01. 21 06:12:20:099 MESZ] J2CA0045E: Connection not available while invoking method queueRequest for resource jdbc/xxxxxxAlso, you have an image service that suddenly throws and prints to another application server the following error: 1[28. 01. 21 17:47:48:647 MESZ] java. lang. Exception: I/O Exception: https://server/imageServiceOnce these documents are indexed into Elasticsearch, the following figure shows an inverted index data structure.  Mapping In order to be able to treat date fields as dates, numeric fields as numbers, and string fields as full-text or exact-value strings, Elasticsearch needs to know what type of data each field contains. This information is contained in the mapping. Index Templates When you create an index template, you tell Elasticsearch which settings and mappings an index should have when it is created. Shards Shards are the physical instances of Apache Lucene, shards take care of the physical storage and retrieval of our data. Nodes and Cluster A node is a running instance of Elasticsearch, while a cluster consists of one or more nodes with the same cluster. name that are working together to share their data and workload. Hot-warm architecture Hot-warm architecture is a way to separate an Elasticsearch deployment into “hot” data nodes and “warm” data nodes. In Hot nodes, You are actively querying and writing to your index. In Warm nodes, You are still querying your index, but it is read-only. In Cold nodes, You are querying your index less frequently. You can deploy it to less performant hardware. We can balance indexing and query performance in Elasticsearch with a hot-warm architecture. JVM Logs: The JVM logs are created by redirecting the System. out and System. err streams of the JVM to independent log files. The System. out log is used to monitor the health of the running application server. The System. err log contains exception stack trace information for problem analysis. Problem: When we need to identify bottlenecks, errors, heavy traffic issues, slow-running queries, connection pooling problems, and more, we usually analyze our application server logs. But this task is tedious because the log files are distributed in a cluster that contains several application servers with their applications. Depending on each application server product, rotating policies for regenerating a log file cause historical records to be lost - data retention period.  If every business area has its cluster, the licenses and number of application servers are exponential. Solution : Hot-warm architecture for log analytics with Elasticsearch: We are going to install a Hot-Warm-Cold Logging Cluster on the Elasticsearch Service as shown in the following figure.  Logs come from multiple sources, such as software applications installed on various application servers. Choosing the right hardware for hot-warm architecture in Elasticsearch: We have the following IP addresses (Three Windows Servers): master  110. 1. 0. 101hotnode 110. 1. 0. 102coldnode 110. 1. 0. 103Open Windows Defender Firewall and add the following rule for the three machines: For the hotnode add an extra 5044 port to the rule if you want to install logstash in that machine. Configure Elasticsearch cluster settings at Master Node: Open …/elasticsearch. yml and copy the following content. bootstrap. memory_lock: truecluster. initial_master_nodes: - masternode. codersite. devcluster. name: elasticprodhttp. port: 9200network. host: 110. 1. 0. 101node. data: falsenode. ingest: falsenode. master: truenode. max_local_storage_nodes: 1node. name: masternode. codersite. devpath. data: E:\ProgramData\Elastic\Elasticsearch\datapath. logs: E:\ProgramData\Elastic\Elasticsearch\logstransport. tcp. port: 9300xpack. license. self_generated. type: basicxpack. security. enabled: falsediscovery. seed_hosts: [ 110. 1. 0. 102:9300 ,  110. 1. 0. 103:9300 ]path. repo: E:\repoCheck the installation with the following command: C:\. . . \codersite. dev&gt;curl -XGET http://110. 1. 0. 101:9200/_cat/health?v=trueepoch   timestamp cluster   status node. total node. data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1611057767 12:02:47 elasticprod green      1     0   0  0  0  0    0       0         -        100. 0%Configure Elasticsearch cluster settings at Hot Node: bootstrap. memory_lock: truecluster. name: elasticproddiscovery. seed_hosts: - 110. 1. 0. 101:9300 - 110. 1. 0. 103:9300http. port: 9200network. host: 110. 1. 0. 102:9300node. data: truenode. ingest: falsenode. master: falsenode. max_local_storage_nodes: 1node. name: hotnode. codersite. devpath. data: E:\ProgramData\Elastic\Elasticsearch\datapath. logs: E:\ProgramData\Elastic\Elasticsearch\logstransport. tcp. port: 9300xpack. license. self_generated. type: basicxpack. security. enabled: falsecluster. initial_master_nodes: masternode. codersite. devpath. repo: E:\reponode. attr. box_type: hotCheck the installation with the following command: C:\. . . \codersite. dev&gt;curl -XGET http://110. 1. 0. 101:9200/_cat/nodes110. 1. 0. 101 4 66 0  lmr   * masternode. codersite. dev110. 1. 0. 102 1 60 8  cdhlrstw - hotnode. codersite. devConfigure Elasticsearch cluster settings at Cold Node: bootstrap. memory_lock: truecluster. name: elasticproddiscovery. seed_hosts: - 110. 1. 0. 101:9300 - 110. 1. 0. 102:9300http. port: 9200network. host: 110. 1. 0. 103node. data: truenode. ingest: falsenode. master: falsenode. max_local_storage_nodes: 1node. name: coldnode. codersite. devpath. data: E:\ProgramData\Elastic\Elasticsearch\datapath. logs: E:\ProgramData\Elastic\Elasticsearch\logstransport. tcp. port: 9300xpack. license. self_generated. type: basicxpack. security. enabled: falsecluster. initial_master_nodes: masternode. codersite. devpath. repo: E:\reponode. attr. box_type: coldCheck the installation with the following command: C:\. . . \codersite. dev&gt;curl -XGET http://110. 1. 0. 101:9200/_cat/nodes110. 1. 0. 101 5 66 0  lmr   * masternode. codersite. dev110. 1. 0. 102 1 60 0  cdhlrstw - hotnode. codersite. dev110. 1. 0. 103 2 66 25  cdhlrstw - coldnode. codersite. devPlease donate to maintain and improve this website if you find this content valuable.   Before we define Index Templates and configure our Index Lifecycle Policies, we must install the Kibana product. Installation and configuration of Kibana: Kibana enables to us navigate through our data (log files) We have installed kibana using a zip package. Check that the following lines are included and activated in the kibana. yml file. C:\&lt;kibana-folder&gt;\config\kibana. yml fileserver. port: 9340server. host:  110. 1. 0. 104 elasticsearch. hosts:  110. 1. 0. 101:9200 To run kibana, execute the following command: C:\&lt;kibana-folder&gt;\bin&gt;kibana. batFrom our local workstations we can access kibana in our browsers using the following url: http://110. 1. 0. 104:9340/Creating index templates We must create and configure our index templates prior to index creation. From Stack Management -&gt; Index Management -&gt; Index Templates, we create a new index template for our billing application log files.  The following snippet code is the final template for new indices whose names match the billing* index pattern. Every time Elasticsearch receive a log file, it transforms it into an index by applying the following settings: {  template : {   settings : {    index : {     lifecycle : {      name :  billing_policy     },     number_of_replicas :  0 ,     routing : {      allocation : {       require : {        box_type :  hot       }     }    }   }  },   mappings : {    properties : {     was_date : {      type :  date ,      format :  dd. MM. yy HH:mm:ss:SSS     }   }  },   aliases : {} }}The routing attribute lets you see which data tier the new indices are allocated to. In our Hot-warm architecture, this will be the Hot Node (box_type attribute). The snippet code also defines a lifecycle to automate when and how to transition an index through our nodes. Data lifecycle management in Elasticsearch: ILM: Manage the index lifecycle We can create and apply Index Lifecycle Management (ILM) policies to automatically manage our indices following our retention requirements. We create a billing policy that defines how to move your data through the following phases.  We want to move our data index to the Cold Node after 30 days from the index’s rollover.  If we want to configure a Delete phase, we must enable the “Delete data after this phase” label. In this Cold phase, we also need to select the node attribute we defined for the Cold Node.  Finally, to save space on our machines, we define a Delete phase to delete our data index after 60 days from the index’s rollover.  Now our index templates and lifecycle policies are ready. Let’s now move on to the sources where the log files come from to Elasticsearch.  Dependency is the key problem in software development. – Software Design, The Art of managing dependencies and Abstractions. Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  Using Logstash to Extract, Transform, and Load Data: Logstash allow us to collect data (log files) from different sources (application servers), and can be enriched, transformed, filtered and moved to elasticsearch. We have installed logstash using a zip package. Logstash will be the receiver for log data from sources such as Beats Agents installed on the Java application servers. We need to create a pipeline (config file) in which we define an input (collect data), a filter (data transformation), and an output (load data into elastic).  Before we create the Logstash pipeline, we’ll configure a Beat Agent called Filebeat to send log lines to Logstash. Configuring Filebeat to Send Log Lines to Logstash: Filebeat is a lightweight shipper for forwarding and centralizing log data. Installed as an agent (service) on our Java application servers, Filebeat monitors the log files, collects log events, and forwards them to Logstash for indexing. We have installed Filebeat with Windows MSI Installer, establishing it as a Windows service. Open the filebeat. yml file in your Filebeat installation directory and replace the content with the following lines. Make sure the paths point to the application server log files. filebeat. inputs:- type: log paths:  - /path/to/logs/billingServer/SystemOut. logoutput. logstash: hosts: [ 110. 1. 0. 102:5044 ] ilm. enabled: trueThe log files that Filebeat processes are redirected - output - to the machine where we will install Logstash. On Windows machines, the absolute path to the log files looks like the following line:  paths:  -  C:\\path\\to\\logs\\billingServer\\SystemOut. log At the application servers machines (data source), run Filebeat with the following command. sudo . /filebeat -e -c filebeat. yml -d  publish Filebeat will attempt to connect Logstash on port 5044. Configuring Logstash for Filebeat Input: Next, we create a primary Logstash configuration pipeline that uses the Beats input plugin to receive events from the application servers and an output section to write to Elasticsearch. input { beats {  port =&gt; 5044 }}# The filter part of this file is commented out to indicate that it is optional. # filter {## }output { stdout { codec =&gt; rubydebug } elasticsearch {  hosts =&gt; [  110. 1. 0. 101:9200  ]   index =&gt;  billing-%{[@metadata][version]}   ilm_policy =&gt;  billing_policy   action =&gt;  create  }}Tu run logstash, execute the following command. C:\&lt;logstash-folder&gt;\bin&gt;logstash -f . . \config\billing-pipeline. conf --config. reload. automaticWith this minimal configuration, you can visualize your log files in Kibana. Please donate if you find this content valuable.   Customizing the filter To use logs data from Elastic to set up a rate-limit algorithm, we need to parse it using filter plugins. We want to know how many requests for every endpoint and client arrive at our application servers by month, day, hour, minute, and second. Grok filter Grok combines text patterns into something that matches your logs. Grok pattern: %{SYNTAX:SEMANTIC} The SYNTAX is the name of the pattern that will match your text. The SEMANTIC is the identifier you give to the matched piece of text. For example, we can pull out fields from a server log file. 55. 3. 244. 1 [19. 08. 22 05:13:42 +0000] codersite. dev GET /v1/api/billings 15824 0. 043The filter section inside logstash pipeline looks like the following. filter { grok {  match =&gt; {  message  =&gt;  %{IP:client} %{DATA:timestamp} %{WORD:client} %{WORD:method} %{URIPATHPARAM:endpoint} %{NUMBER:bytes} %{NUMBER:duration}  } }  grok {  match =&gt; [ timestamp ,  %{WORD:was_dd}. %{WORD:was_MM}. %{WORD:was_yy} %{SPACE}%{WORD:was_HH}:%{WORD:was_mm}:%{WORD:was_ss} ] }}We build an aggregation that summarizes our data. The following search runs a terms aggregation on “codersite. dev” client. GET . ds-billing-index-000006/_search{  size : 0,   query : {   match : {    client. keyword :  codersite. dev   } },  aggs : {   all_clients : {    terms : {     field :  client. keyword    },    aggs : {     all_endpoints : {      terms : {       field :  endpoint. keyword      },      aggs : {       all_was_years : {        terms : {         field :  was_yy. keyword        },        aggs : {         all_was_months : {          terms : {           field :  was_MM. keyword          },          aggs : {           all_was_days : {            terms : {             field :  was_dd. keyword            },            aggs : {             all_was_hours : {              terms : {               field :  was_HH. keyword              },              aggs : {               all_was_minutes : {                terms : {                 field :  was_mm. keyword                }                   }             }            }           }          }         }        }       }      }     }    }   }  } }} Aggregation results are in the response’s aggregations object. {  took  : 1253,  timed_out  : false,  _shards  : {   total  : 1,   successful  : 1,   skipped  : 0,   failed  : 0 },  hits  : {   total  : {    value  : 10000,    relation  :  gte   },   max_score  : null,   hits  : [ ] },  aggregations  : {   all_clients  : {    doc_count_error_upper_bound  : 0,    sum_other_doc_count  : 0,    buckets  : [    {      key  :  codersite. dev ,      doc_count  : 2310409,      all_endpoints  : {       doc_count_error_upper_bound  : 0,       sum_other_doc_count  : 0,       buckets  : [       {         key  :  /v1/api/billings ,         doc_count  : 2309966,         all_was_years  : {          doc_count_error_upper_bound  : 0,          sum_other_doc_count  : 0,          buckets  : [          {            key  :  23 ,            doc_count  : 2309966,            all_was_months  : {             doc_count_error_upper_bound  : 0,             sum_other_doc_count  : 0,             buckets  : [             {               key  :  09 ,               doc_count  : 1516918,               all_was_days  : {                doc_count_error_upper_bound  : 0,                sum_other_doc_count  : 712935,                buckets  : [                {                  key  :  13 ,                  doc_count  : 80457,                  all_was_hours  : {                   doc_count_error_upper_bound  : 0,                   sum_other_doc_count  : 0,                   buckets  : [                   {                     key  :  06 ,                     doc_count  : 10061,                     all_was_minutes  : {                      doc_count_error_upper_bound  : 0,                      sum_other_doc_count  : 1146,                      buckets  : [                      {                        key  :  17 ,                        doc_count  : 939                      },                      {                        key  :  18 ,                        doc_count  : 916                      },                      {                        key  :  26 ,                        doc_count  : 840                      }                     ]                    }                   },                   {                     key  :  21 ,                     doc_count  : 10061,                     all_was_minutes  : {                      doc_count_error_upper_bound  : 0,                      sum_other_doc_count  : 1461,                      buckets  : [                      {                        key  :  18 ,                        doc_count  : 889                      },                      {                        key  :  19 ,                        doc_count  : 882                      }										 ]                    }                   }                  ]                 }                }               ]              }             }            ]           }          }         ]        }       }      ]     }    }   ]  } }}									From the buckets per minute, we can see codersite. dev client sends an average of 893 requests per minute. Based on these accurate statistics and analyses, you know how to limit the number of requests allowed per client + endpoint. In this way, you can protect your software infrastructure from possible attacks or overuse of hardware resources. Learn here how to implement a RateLimit algorithm. Now that you have centralized all server logs in only one cluster, you can monitor or diagnose possible errors. Kibana will inform you about all application servers’ errors in one unified report. Please donate if you find this content valuable.   "
    }, {
    "id": 33,
    "url": "http://localhost:4000/clean-code/",
    "title": "Best practices for writing Clean Code",
    "body": "2020/10/27 - Clean code can be read and enhanced by a developer other than its original author. This kind of practice Robert C Martin introduced it. If you want to be a better programmer, you must follow these recommendations. Clean Code has Intention-Revealing names: Names reveal intent. Someone who reads your code must understand the purpose of your variable, function, or class. Real situation: 12int sId; //supplier Idint artDelPrice;It must be refactored to this: 12int supplierId;int articleDeliveredPrice;Even with external dependencies: 1private Z_E2F_RS_Result e2fResult; //ingredients recordsetIt must be refactored to this: 1private Z_E2F_RS_Result ingredients;Imagine that we dont have the //ingredients comment in e2fResult variable. Then, further in any part of our code, when we try to process this variable, we have the following sentence: 1e2f = e2fResult[i];And we don’t know what does e2f means!. Well, someone suggests asking the person responsible for this code. But that guy is not at the office. Well, send it an email, and he is on holiday!. But if instead we adopt names which reveal intent from beginning, we could avoid these catastrophic scenarios. 1ingredient = ingredients[i];Clean Code tells a story: When we try to fix bugs, when analyzing the secuence of actions (functions, methods), we realize the code does not communicate well the logical flow of these actions. It’s a nightmare to decode the meaning of these actions. This will always happen because our initial design based on the initial requirements change over time. As developers, we are responsible for refactoring our code to made it a simple story that everybody can understand. For example, look at the following code: 1234567891011ACMEWebServiceClient. login();if (process. equals( core ) {  ACMEWebServiceClient. transfer_buyersCoreData_to_ACME();}if (process. equals( status )) {  ACMEWebServiceClient. transfer_buyersStatusChanges_to_ACME();}if (process. equals( events )) {  ACMEWebServiceClient. transfer_events_to_ACME();}ACMEServiceClient. logout();Functions should do one thing: Imagine we want to retrieve image objects from an external web service. Firstly, we receive image metadata that informs different values to decide if an image is valid or not, and one of these values is an image identifier to retrieve the final image object. 1234567891011121314151617private String retrieveImageId(String[] values) {  if (!values[2]. equals( Y ) || !values[3]. equals( Y ))  return null;	  String imageId = null;  //get the first not null value as the imageId  if (values[4] != null) {   imageId = values[4]; //imageAIXId  } else if (values[5] != null) {   imageId = values[5]; //imageLIXId  } else if (values[6] != null) {   imageId = values[6]; //imageOIXId  }  return imageId;}The previous code is doing more than one thing: validate and retrieve. Each thing should implement only one level of abstraction. Therefore we proceed to refactor it. 1234567private boolean validateImage(String[] values) {  if (!values[2]. equals( Y ) || !values[3]. equals( Y ))  return false;	 return true;}1234567891011121314private String retrieveImageId(String[] values) {  String imageId = null; //get the first not null value as the immageId if (values[4] != null) {  imageId = values[4]; //imageAIXId } else if (values[5] != null) {  imageId = values[5]; //imageLIXId } else if (values[6] != null) {  imageId = values[6]; //imageOIXId } return imageId;}Here is an example of how to use these new smaller functions. 12345678910111213public void syncronizeImages () {  Response response = api. getImages(); Row[] rows = response. getRows(); for (Row row : rows) {  String[] values = row. getValues();  if (validateImage(values)) {   String imageId = retrieveImageId(values);   //call ULR to retrieve image object   //code omitted for brevity  } }}Don’t comment bad code, rewrite it: Imagine you requested metadata from a list of articles, but the external API, for any reason, includes additional articles in its response object. Before processing their metadata, you want to check that retrieved articles are inside your temporal map of requested articles. Introduces a comment to alert your colleagues. 123456789101112131415public void syncronizeImages () { Response response = api. getImages(mapOfArticles); Row[] rows = response. getRows(); for (Row row : rows) {  String[] values = row. getValues();  String articleId = values[1];    //only requested articles  if (!mapOfArticles. containsKey(articleId))   continue;	   //code omitted for brevity }}You can avoid this extra unnecessary comment if you express in your code what you want to communicate by renaming the map variable name. 1234567891011121314public void syncronizeImages () { Response response = api. getImages(mapOfRequestedArticles); Row[] rows = response. getRows(); for (Row row : rows) {  String[] values = row. getValues();  String articleId = values[1];    if (!mapOfRequestedArticles. containsKey(articleId))   continue;	   //code omitted for brevity }}Now, your code is more expressive. Choose simplicity over complexity: As developers, sometimes we use ternary conditional operators that take less space, but when we introduce more variables, the code is not readable or is more difficult to evolve. For example, when we try to build the article’s image URL, we need to evaluate if an image is valid and if the image is not restricted; if it is restricted, we need to assess whether a partner can retrieve this image. 1String articleImageURL = (imageId &lt;= 0 || (imageIdIsRestricted &amp;&amp; !partnerCanSeeImage)) ? null : IMAGE_URL + imageId;The previous code can be refactored using nested if-else statements, which is easier to understand. 12345678910String articleImageURL = null;if (imageId &gt; 0) { if (imageIdIsRestricted) {  if (partnerCanSeeImage) {   articleImageURL = IMAGE_URL + imageId;  } } else {  articleImageURL = IMAGE_URL + imageId; }}Even the KISS (Keep It Simple, Stupid) principle suggests that developers should strive for simplicity and avoid unnecessary complexity. This makes code easier to understand, maintain, and debug.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  Avoid hard coding: Hard coding is embedding data directly into the source code instead of obtaining the data from external sources. Sometimes we can’t avoid including conditional statements using hardcoded values because we need to implement them in a production environment immediately. There are hundreds of reasons why this happens because every company is different. A company wants to implement in its code validation of customers who have the right to view images from certain providers. The standard procedure in this company starts with a requirement to the DBA to implement a database function to retrieve a list of providers with this kind of restriction, create param classes for the developers, a period of implementation in a development environment, and its tests in a test environment, and deliver to the production environment. But the company is facing problems with image author property rights and does not have the resources to implement the requirement, then decides to introduce hard-coded values. 1 boolean picIsRestricted = result. getProviderId() ==  530636  || result. getProviderId() ==  36507 ; We usually forget the standard procedure to implement the solution because our code is already working. But these hard code values are required in other modules, packages, and classes and may need to validate more providers, etc. , and the effort to maintain the code increase exponentially. And I think you know the rest of the history. You can implement a little function to retrieve external data from a text file. 12345public interface DataService { public List&lt;String&gt; getRestrictedProviders() throws Exception;}Then, you can implement your hard-coded values in an implementation class. 123456789101112131415161718public class DataServiceImpl implements DataService { @Override public List&lt;String&gt; getRestrictedProviders() throws Exception {  List&lt;String&gt; listOfRestrictedProviders = new ArrayList&lt;&gt;();  Resource resource = new ClassPathResource( providers. txt );   try {    List&lt;String&gt; allLines = Files. readAllLines(Paths. get(resource. getURI()));    for (String provider : allLines) {     listOfRestrictedProviders. add(provider);     //TODO retrieve data from a standard database function    }   } catch (IOException e) {    e. printStackTrace();   }  return listOfRestrictedProviders; }}Then, you can always reuse the same validation in any place of your code. 123456 List&lt;String&gt; listOfRestrictedProviders = dataService. getRestrictedProviders(); boolean picIsRestricted = listOfRestrictedProviders. contains(result. getProviderId());}The day you decide to implement the standard procedure - database function - your effort in refactoring your code will be minimal. Name your variables according to the context: It is usual to have an attribute that applies to two different objects. For example, an Buyer Object has an email address. 12345678public class Buyer { private int buyerId; private String lastName; private String email;  //code omitted for brevity}We can see the same attribute in a Supplier Object. 12345678public class Supplier { private int supplierId; private String contact; private String email;  //code omitted for brevity}When retrieving an email from a supplier object, we may lose the context. 1String email = supplier. getEmail();Further in our code, we may be unsure if the email variable refers to a Supplier or a Buyer. I prefer to define the schemas of our Objects based on the context. 12345678public class Buyer { private int buyerId; private String buyerLastName; private String buyerEmail;  //code omitted for brevity}We do the same for the Supplier object. 12345678public class Supplier { private int supplierId; private String supplierContact; private String supplierEmail;  //code omitted for brevity}The most advanced editors provide coding assistance features such as variable name suggestions as you type. 123String supplierEmail = supplier. getSupplierEmail();String buyerEmail = buyer. getBuyerEmail();Method Overloading: Suppose we already have a function communicating well with an external service. We send data to subscribe to the external service for a new buyer. 123public int subscribe(String email, Buyer buyer) { //code omitted for brevity}This function is called from several parts of a program. 12subscriberId = WSClient. subscribe(email, buyer);}Now, we want to send new buyers, but at the same time, we want to inform the external service to take action based on a specific tagged attribute. If we decide to refactor the function to accept a new argument, we need to change our program in all parts that call the function, even when they dont need to pass the new attribute. 12subscriberId = WSClient. subscribe(email, buyer, null);}We can introduce a new function with the same name but with a new parameter. 1234567public int subscribe(String email, Buyer buyer, Integer tagId) { //code omitted for brevity}public int subscribe(String email, Buyer buyer) { //code omitted for brevity}Only new parts of the program that need to use the new functionality call the new method. 12subscriberId = WSClient. subscribe(email, buyer, 102911);}Method overloading increases the readability and reusability of the program. Avoid Too Many Arguments In Functions: Sometimes, we write functions containing more than three arguments, like this function: 123public boolean validateAddress(String street, int number, String postalCode, String city, String country) { //code omitted for brevity}As all these arguments belong to an Address concept, we can pass an Object as an argument. 123public boolean validateAddress(Address address) { //code omitted for brevity}Applications of clean code:  Refactoring techniques for improving code cleanliness Achieving maintainability through clean code practices Clean code practices for agile software development teams Code review checklist for ensuring clean code Clean code in object-oriented programming Clean code practices for improving software security Clean code practices for improving code collaboration Clean code and continuous integration/continuous deployment (CI/CD)Please donate to maintain and improve this website if you find this content valuable.   You can see a lot of typical algorithms implemented with Clean Code principles in the following link  "
    }, {
    "id": 34,
    "url": "http://localhost:4000/documenting-rest-api-openapi3/",
    "title": "Documenting a SpringBoot REST API with OpenAPI 3",
    "body": "2020/10/02 - The main idea for documenting our back-end RESTful APIs is to communicate to third-party developers what our endpoints are doing. To learn more about REST API design, see REST API Overview. In this tutorial, we are going to write clear and concise API documentation using OpenAPI 3. Prerequisites:  Java 8. x Maven 3. xSteps: 1. Create the maven project: Go to spring initializr and add the following dependencies: Once you generate the JAR maven project, open it in your favorite IDE. Below, you can see the pom. xml to use: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version= 1. 0  encoding= UTF-8 ?&gt;&lt;project xmlns= http://maven. apache. org/POM/4. 0. 0  xmlns:xsi= http://www. w3. org/2001/XMLSchema-instance 	xsi:schemaLocation= http://maven. apache. org/POM/4. 0. 0 https://maven. apache. org/xsd/maven-4. 0. 0. xsd &gt;	&lt;modelVersion&gt;4. 0. 0&lt;/modelVersion&gt;	&lt;parent&gt;		&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;		&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;		&lt;version&gt;2. 3. 4. RELEASE&lt;/version&gt;		&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;	&lt;/parent&gt;	&lt;groupId&gt;com&lt;/groupId&gt;	&lt;artifactId&gt;openapi&lt;/artifactId&gt;	&lt;version&gt;0. 0. 1-SNAPSHOT&lt;/version&gt;	&lt;name&gt;openapi&lt;/name&gt;	&lt;description&gt;openapi in Spring Boot&lt;/description&gt;	&lt;properties&gt;		&lt;java. version&gt;1. 8&lt;/java. version&gt;	&lt;/properties&gt;	&lt;dependencies&gt;		&lt;dependency&gt;			&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;			&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;		&lt;/dependency&gt;		&lt;dependency&gt;			&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;			&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;			&lt;scope&gt;test&lt;/scope&gt;			&lt;exclusions&gt;				&lt;exclusion&gt;					&lt;groupId&gt;org. junit. vintage&lt;/groupId&gt;					&lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;				&lt;/exclusion&gt;			&lt;/exclusions&gt;		&lt;/dependency&gt;		&lt;dependency&gt;			&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;			&lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;		&lt;/dependency&gt;		&lt;dependency&gt;			&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;			&lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;		&lt;/dependency&gt;		&lt;dependency&gt;			&lt;groupId&gt;com. h2database&lt;/groupId&gt;			&lt;artifactId&gt;h2&lt;/artifactId&gt;			&lt;scope&gt;runtime&lt;/scope&gt;		&lt;/dependency&gt;	&lt;/dependencies&gt;	&lt;build&gt;		&lt;plugins&gt;			&lt;plugin&gt;				&lt;groupId&gt;org. springframework. boot&lt;/groupId&gt;				&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;			&lt;/plugin&gt;		&lt;/plugins&gt;	&lt;/build&gt;&lt;/project&gt;To generate the API documentation with OpenAPI 3, we add the springdoc-openapi-ui dependency to our pom. xml file. The main idea for documenting our back-end RESTful APIs is to communicate what our endpoints are doing to third-party developers. 12345&lt;dependency&gt;  &lt;groupId&gt;org. springdoc&lt;/groupId&gt;  &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt;  &lt;version&gt;1. 3. 9&lt;/version&gt;&lt;/dependency&gt;2. Configure H2 Database: The H2 in-memory database is volatile, which means data will be lost when we restart the application. We add the following properties to the application. properties file. 12345spring. datasource. url=jdbc:h2:mem:testdbspring. datasource. driverClassName=org. h2. Driverspring. datasource. username=saspring. datasource. password=passwordspring. jpa. database-platform=org. hibernate. dialect. H2Dialect3. Create JPA Entity – Book. java: JPA stands for Java Persistence API and is a Java specification about how to handle relational data. Even when Spring Data provides a standard programming model for different databases, switching from a SQL database to a NoSQL database is impossible without touching the source code. @Entity annotation describes the Book data that will be stored by Spring Data and makes our Book object ready for storage in a JPA-based relational data store. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com. openapi. model;import com. fasterxml. jackson. annotation. JsonProperty;import io. swagger. v3. oas. annotations. media. Schema;import javax. persistence. *;import javax. validation. constraints. NotBlank;import javax. validation. constraints. Size;@Schema(description =  Book object )@Entity@Table(name= books )public class Book { @JsonProperty(value= id , required=true, index = 10) @Schema(description =  Unique identifier of the Book.  ,   example =  1 , required = true) private long id; @JsonProperty(value= title , required=true, index = 20) @Schema(description =  Name of the title.  ,   example =  Java , required = true) @NotBlank @Size(min = 0, max = 20) private String title; @JsonProperty(value= author , required=true, index = 30) @Schema(description =  Name of the author.  ,   example =  Max Abi , required = true) @NotBlank @Size(min = 0, max = 30) private String author; public Book() {} @Id @GeneratedValue(strategy = GenerationType. AUTO) public long getId() {  return id; } public void setId(long id) {  this. id = id; } @Column(name =  title , nullable = false) public String getTitle() {  return title; } public void setTitle(String title) {  this. title = title; } @Column(name =  author , nullable = false) public String getAuthor() {  return author; } public void setAuthor(String author) {  this. author = author; }}4. Create a String Data Repository – BookRepository. java: Repositories are used to store and access data from different types of databases. Spring Data JPA repository supports creating, reading, updating, and deleting records against our back-end datastore. 123456package com. openapi. respository;import com. openapi. model. Book;import org. springframework. data. jpa. repository. JpaRepository;import org. springframework. stereotype. Repository;@Repositorypublic interface BookRepository extends JpaRepository&lt;Book, Long&gt; {}5. Create Spring Rest Controller Interface – BookApi: We create an Interface to describe the API functionalities with the openapi annotations. In this way, we separate our API contract from the implementation Class. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com. openapi. controller;import com. openapi. model. Book;import io. swagger. v3. oas. annotations. Operation;import io. swagger. v3. oas. annotations. Parameter;import io. swagger. v3. oas. annotations. media. Content;import io. swagger. v3. oas. annotations. media. Schema;import io. swagger. v3. oas. annotations. responses. ApiResponse;import io. swagger. v3. oas. annotations. responses. ApiResponses;import io. swagger. v3. oas. annotations. tags. Tag;import org. springframework. http. HttpStatus;import org. springframework. http. ResponseEntity;import org. springframework. web. bind. annotation. *;import javax. validation. Valid;import javax. validation. constraints. NotNull;import java. util. Collection;@Tag(name =  book , description =  the book API )@RequestMapping( /api/v1/books )public interface BookApi { @Operation(summary =  Find book by ID , description =  Returns a single book , tags = {  book  }) @ApiResponses(value = {   @ApiResponse(responseCode =  200 , description =  successful operation , content = @Content(schema = @Schema(implementation = Book. class))),   @ApiResponse(responseCode =  400 , description =  Invalid ID supplied , content = @Content),   @ApiResponse(responseCode =  404 , description =  Book not found , content = @Content) }) @RequestMapping(value =  /{id} , produces = {  application/json ,  application/vnd. api+json }, method = RequestMethod. GET) @ResponseStatus(HttpStatus. OK) public ResponseEntity&lt;Book&gt; findById(   @Parameter(description =  ID of book , required = true)   @PathVariable long id,   @NotNull @Parameter(description =  select which kind of data to fetch , required = true)   @Valid @RequestHeader(value= bookAuthorization , required = true) String bookAuthorization)   throws Exception; @Operation(summary =  Get books , description =  Returns a books collection , tags = {  book  }) @GetMapping( / ) @ResponseStatus(HttpStatus. OK) public Collection&lt;Book&gt; findBooks(); @PutMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public Book updateBook(@PathVariable( id ) final String id, @RequestBody final Book book); @PatchMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public Book patchBook(@PathVariable( id ) final String id, @RequestBody final Book book); @Operation(summary =  Create book , description =  This can only be done by the logged in book.  , tags = {  book  }) @ApiResponses(value = { @ApiResponse(description =  successful operation , content = { @Content(mediaType =  application/json , schema = @Schema(implementation = Book. class)), @Content(mediaType =  application/xml , schema = @Schema(implementation = Book. class)) }) }) @PostMapping(value =  / , consumes = {  application/json ,  application/xml ,  application/x-www-form-urlencoded  }) @ResponseStatus(HttpStatus. CREATED) public ResponseEntity&lt;Book&gt; postBook(   @NotNull   @Parameter(description =  Created book object , required = true)   @Valid @RequestBody Book body,   @NotNull @Parameter(description =  select which kind of data to fetch , required = true)   @Valid @RequestHeader(value= bookAuthorization , required = true) String bookAuthorization)   throws Exception; @RequestMapping(method = RequestMethod. HEAD, value =  / ) @ResponseStatus(HttpStatus. OK) public Book headBook(); @DeleteMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public long deleteBook(@PathVariable final long id);} Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  6. Create Spring Rest Controller Implementation – BookApiController. java: @RestController annotation tells Spring that this Class describes endpoints that should be made available over the web. The data returned by each method will be included in the response body. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com. openapi. controller;import java. util. Collection;import com. openapi. exception. BookNotFoundException;import com. openapi. model. Book;import com. openapi. respository. BookRepository;import org. springframework. beans. factory. annotation. Autowired;import org. springframework. http. HttpStatus;import org. springframework. http. ResponseEntity;import org. springframework. web. bind. annotation. DeleteMapping;import org. springframework. web. bind. annotation. PatchMapping;import org. springframework. web. bind. annotation. PathVariable;import org. springframework. web. bind. annotation. PutMapping;import org. springframework. web. bind. annotation. RequestBody;import org. springframework. web. bind. annotation. RequestMapping;import org. springframework. web. bind. annotation. RequestMethod;import org. springframework. web. bind. annotation. ResponseStatus;import org. springframework. web. bind. annotation. RestController;@RestControllerpublic class BookApiController implements BookApi { @Autowired private BookRepository repository; @Override public ResponseEntity&lt;Book&gt; findById(   long id,   String bookAuthorization) throws Exception {  Book book = repository. findById(id)    . orElseThrow(() -&gt; new BookNotFoundException( Employee not found for this id ::   + id));  return ResponseEntity. ok(). body(book); } @Override public Collection&lt;Book&gt; findBooks() {  return repository. findAll(); } @PutMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public Book updateBook(@PathVariable( id ) final String id, @RequestBody final Book book) {  return book; } @PatchMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public Book patchBook(@PathVariable( id ) final String id, @RequestBody final Book book) {  return book; } @Override public ResponseEntity&lt;Book&gt; postBook(   Book body,   String bookAuthorization) throws Exception {  return new ResponseEntity&lt;Book&gt;(repository. save(body), HttpStatus. CREATED); } @RequestMapping(method = RequestMethod. HEAD, value =  / ) @ResponseStatus(HttpStatus. OK) public Book headBook() {  return new Book(); } @DeleteMapping( /{id} ) @ResponseStatus(HttpStatus. OK) public long deleteBook(@PathVariable final long id) {  return id; }}7. Configure openApi – OpenApiConfig. java: The OpenAPI class is the root document object that describes an API or elements of an API 123456789101112131415161718192021222324package com. openapi. config;import io. swagger. v3. oas. models. info. Info;import io. swagger. v3. oas. models. Components;import io. swagger. v3. oas. models. OpenAPI;import io. swagger. v3. oas. models. info. Contact;import io. swagger. v3. oas. models. info. License;import org. springframework. context. annotation. Bean;import org. springframework. context. annotation. Configuration;@Configurationpublic class OpenApiConfig { @Bean public OpenAPI customOpenAPI() {  return new OpenAPI()    . components(new Components())    . info(new Info()      . title( Book Application API )      . description( This is a sample Spring Boot RESTful service using springdoc-openapi and OpenAPI 3.  )      . termsOfService( terms )      . contact(new Contact(). email( codersitedev@gmail. com ))      . license(new License(). name( GNU ))      . version( 1. 0 )    ); }}8. Running Application: This Spring boot application has an entry point Java class called OpenapiApplication. java, which you can run to start the application. 123456789package com. openapi;import org. springframework. boot. SpringApplication;import org. springframework. boot. autoconfigure. SpringBootApplication;@SpringBootApplicationpublic class OpenapiApplication {	public static void main(String[] args) {		SpringApplication. run(OpenapiApplication. class, args);	}} @SpringBootApplication add the following functionalities:  OpenApiApplication Class becomes a Configuration class.  It enables Component scan, which means looking for other components, configurations, controllers, and services in the com. openapi package.  It enables autoconfiguration; Spring Boot looks for other JAR files in the classpath and configures it automatically, e. g. , H2 database, JPA. Spring Boot will detect and start an embedded Tomcat webserver. 2021-10-28 12:48:02. 659 INFO 9312 --- [ restartedMain] . s. d. r. c. RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFERRED mode. 2021-10-28 12:48:02. 881 INFO 9312 --- [ restartedMain] . s. d. r. c. RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 201ms. Found 1 JPA repository interfaces. 2021-10-28 12:48:04. 812 INFO 9312 --- [ restartedMain] o. s. b. w. embedded. tomcat. TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2021-10-28 12:48:04. 847 INFO 9312 --- [ restartedMain] o. apache. catalina. core. StandardService  : Starting service [Tomcat]2021-10-28 12:48:04. 848 INFO 9312 --- [ restartedMain] org. apache. catalina. core. StandardEngine : Starting Servlet engine: [Apache Tomcat/9. 0. 38]2021-10-28 12:48:05. 131 INFO 9312 --- [ restartedMain] o. a. c. c. C. [Tomcat]. [localhost]. [/]    : Initializing Spring embedded WebApplicationContext. . . 2021-10-28 12:48:11. 700 INFO 9312 --- [ restartedMain] o. s. b. w. embedded. tomcat. TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2021-10-28 12:48:11. 703 INFO 9312 --- [ restartedMain] DeferredRepositoryInitializationListener : Triggering deferred initialization of Spring Data repositories…2021-10-28 12:48:12. 668 INFO 9312 --- [ restartedMain] DeferredRepositoryInitializationListener : Spring Data repositories initialized!2021-10-28 12:48:12. 704 INFO 9312 --- [ restartedMain] com. openapi. OpenapiApplication      : Started OpenapiApplication in 14. 363 seconds (JVM running for 18. 621)Then, when we run our application, we can see the online documentation at: http://localhost:8080/swagger-ui. html OpenAPI includes a “Try it out” button, which can be used to actually try out the API, not just read its documentation. You can see the source code in the following link: https://github. com/mgamio/openapi-springboot. git Most of the companies usually follow a Design-First API Strategy using SwaggerHub product for example. But the export plugins are not always aligned with the most updated version of OpenAPI. Once you receive the technical specifications in UML, you need to decide whether to take the Design First approach or the Code First approach. Documenting API endpoints with OpenAPI 3 facilitates interaction between internal development teams that build different web services for the same product. Please donate to maintain and improve this website if you find this content valuable.   Let’s now see how to integrate OAuth2 to protect our endpoints. "
    }, {
    "id": 35,
    "url": "http://localhost:4000/big-o-notation-analysis-of-algorithms/",
    "title": "Big O Notation and Analysis of Algorithms - coding interview",
    "body": "2020/06/22 - Big O Notation is a mathematical notation that helps us analyze how complex an algorithm is in terms of time and space. When we build an application for one user or millions of users, it matters. We implement different algorithms to solve one problem and measure how efficient is one respect to the other ones. Algorithm analysis is an essential part of computational complexity theory, which aims to quantify the resources required to solve computational problems. The first study about Analysis of Algorithms was published by Knuth in 1968. The Art of Computer Programming. Asymptotic Notation is used to describe the running time of an algorithm. There are three different notations: Big Omega, Big Theta, and Big O Notation. Time complexity analysis and space complexity analysis: Time complexity analysis is related to how many steps takes an algorithm. Space complexity analysis is related to how efficient an algorithm is using the memory and disk. Both terms depend on the input size, the number of items in the input. Both terms depend on the input size and the number of items in the input. Moreover, we can analyze the complexity based on three cases or asymptotic notations. :    Best case or Big Omega Ω(n): Usually the algorithm executes in one step independently of the input size.     Average case or Big Theta Θ(n): If the the input size is ramdom     Worst-case analysis or Big O Notation O(n): Gives us an upper bound on the runtime for any input. It gives us a kind of guarantee that the algorithm will never take any longer with a new input size.  Order of growth: The order of growth is related to how the runtime of an algorithm increases when the size of the input increases without limit and tells us how efficient the algorithm is. Therefore, we can compare the relative performance of alternative algorithms. Big O Notation: Common order-of-growth classifications: Big O Notation: examples: O(1) – Constant It does not matter if the input contains 1000 or 1 million items, the code always executes in one step. 123public void constant(List&lt;string&gt; list, String item) { list. add(item);} In a best-case scenario, an add method takes O(1) time. The worst-case scenario takes O(n). O(N) – linear An algorithm runs in O(N) time if the number of steps depends on the number of items included in the input. 1234567public int sum(int[] numbers) { int sum =0; for (int i =0; i&lt;numbers. length; i++) {  sum+=numbers[i]; } return sum;}The main idea in Analysis of Algorithms is always to improve the algorithm performance, by reducing the number of steps and comparisons. You can visit find the smallest number with the same number of digits, for instance. Moreover, the simpler and more intuitive an algorithm is, the more useful and efficient it will be. O(N2) – quadratic If an algorithm includes two loops nested in its code, we could say that it’s running in quadratic time O(N2). For instance, when a 2D matrix is initialized in a tic-tac-toe game. 12345678910private String [][] board;public void initializeBoard(int size) { this. board = new String[size][size]; for (int x = 0; x &lt; size; x++) {  for (int y = 0; y &lt; size; y++) {   board[x][y] =    ;  } }}O(N3) – Cubic When the code includes at the most three nested loops, then the algorithm runs in Cubic time. For example: given N integers, how many triples sum to exactly zero?. One approach (not the best) is to use three nested loops. 1234567891011public int countThreeSum(int[] numbers) { int N =numbers. length; int count =0; for (int i = 0; i&lt;N; i++)  for (int j = i+1; j&lt;N; j++)   for (int k = j+1; k&lt;N; k++)    if (numbers[i] + numbers[j] + numbers[k] == 0)     count++; return count;}O(LogN) – logarithmic This kind of algorithm produces a growth curve that peaks at the beginning and slowly flattens out as the size of the input increase. Log28 = 3 Log216 = 4 Log232 = 5 Analysis of searching algorithms The binary search uses at most LogN key compares to search in a sorted array of size N. With 8 elements take 3 comparisons, with 16 elements takes 4 comparisons, with 32 elements takes 5 comparisons, and so on. 123456789101112131415public static &lt;T extends Comparable&lt;T&gt;&gt; boolean search(T target, T[] array) { int min = 0; int max = array. length - 1; while (min &lt;= max) {  int mid = (min + max) / 2;  if (target. compareTo(array[mid]) &lt; 0) {   max = mid - 1;  } else if (target. compareTo(array[mid]) &gt; 0) {   min = mid + 1;  } else {   return true;  } } return false;} The complexity of an algorithm: To find the Big O complexity of an algorithm follows the following rules:  Ignore the lower order terms Drop the leading constantsExample: If the time complexity of an algorithm is 2n3 + 4n + 3. Its Big O complexity simplifies to O(n3). How to find the time complexity of an algorithm Given the following algorithm: 12345678public Integer sumEvenNumbers(Integer N) { int sum = 0; for (int number = 1; number &lt;= N; number++)  if ((number % 2) == 0)   sum = sum + number; return sum;}First, we split the code into individual operations and then compute how many times it is being executed as is shown in the following table.       Description   Number of executions         int sum = 0;   1       int number = 1;   1       number &lt;= N;   N       number++   N       if ((number % 2) == 0)   N       sum = sum + number;   N       return sum;   1               Now, we need to sum up how many times each operation is executing. Time complexity = 1 + 1 + N + N + N + N + 1 =&gt;  4N + 3 Why Big O Notation ignores constants?: Big O Notation describes how many steps are required relative to the number of data elements. And it serves as a way to classify the long-term growth rate of algorithms. For instance, for all amounts of data, O(N) will be faster than O(N2) as shown in the following figure: Now, if we compare O(100N) with O(N2), we can see that O(N2) is faster than O(100N) for some amounts of data as shown in the following figure: But after an intersection point, O(100N) becomes faster and remains faster (in terms of the “number of steps”) for all increasing amounts of data from that point onward. And that is the reason why Big O Notation ignores constants. Because of this, the value of 100 is irrelevant and O(100N) is written as O(N). The fewer steps, the faster the algorithm. This article was just an introduction to algorithm analysis to face an actual code interview as a software developer. They are asked to build approximated models using Big O notation in Java. The same concepts apply to Python algorithm analysis. If you want to create a mathematical model for the execution time of a discrete operation, for example, you should take a course in discrete mathematics. Please donate to maintain and improve this website if you find this content valuable.   Preparing to discuss algorithms analysis in your following programming interview requires practicing and studying different algorithms, and you can find it in this link with many explanation details. "
    }, {
    "id": 36,
    "url": "http://localhost:4000/solid-principles-the-definitive-guide/",
    "title": "SOLID principles: The Definitive Guide (Part I)",
    "body": "2020/06/15 - SOLID principles tell you how to arrange your functions into classes and how those classes should be interrelated. SOLID is an acronym that stands for five principles of software design: Single Responsibility, Open-Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion. Robert C. Martin introduced it. Clean Architecture. When SOLID principles are applied correctly, your software infrastructure will tolerate changes, be easier to understand, and focus on reusable components by reducing complexity, coupling, and dependency. Let’s start with the first principle. SOLID principles: Single Responsibility Principle (SRP):  … “a class should only have one reason to change“ This principle states that a class should only have one responsibility. For instance, imagine an online store that issues its cards for its customers, and from the beginning, the Payment and Card teams are in mutual agreement to apply for interest and to lock cards from customers who are in late payments for 14 days or more. In the following code, we have the first design of the Payment Class, which supports both requirements. 12345678910111213public class Payment { public static final int MAX_DAYS = 14;  public void batch(List&lt;Customer&gt; customers) {  for (Customer customer : customers) {   int nDays = latePaymentDays(customer);   if (nDays &gt;= MAX_DAYS) {    applyLatePaymentInterest(customer);    lockCard(customer);   }  } }}The Problem: A Class has more than one responsibility: But suddenly, the Cards team wants to change the validation to 10 days. However, the Payments team manages other policies related to when interests by late payment are applied. As a result, the Payments team disagrees with the Cards team. Moreover, both teams are stuck on how to proceed. This scenario is a clear example of how this Class design violates the Single Responsibility Principle. The Payment class has more than one reason to change and breaks the Payments team’s business logic if they accept the Cards team’s requirement. The following figure shows the Class with different responsibilities: The solution: Create a Class with only one responsibility: What do we need to do?. In this scenario, we can apply the Single Responsibility Principle Firstly, we move the lockCard() responsibility to a new Card Class. This technique is most known as refactoring 123456789101112public class Card { public static final int MAX_DAYS = 10;  public void batch(List customers) {  for (Customer customer : customers) {   int nDays = Payment. latePaymentDays(customer);   if (nDays &gt;= MAX_DAYS) {    lockCard(customer);   }  } }}After that change and following Clean code principles, we can see how it looks the new Payment Class (refactored as well): 123456789101112public class Payment { public static final int MAX_DAYS = 14;  public void batch(List&lt;Customer&gt; customers) {  for (Customer customer : customers) {   int nDays = latePaymentDays(customer);   if (nDays &gt;= MAX_DAYS) {    applyLatePaymentInterest(customer);   }  } }}Finally, new changes to the MAX_DAYS variable will only depend on the requirements of every team separately. The following figure shows the Classes for different actors, without conflicts.  Therefore, the Payment Class is only responsible for supporting to the Payments team, and the Card Class is solely responsible for supporting the Cards team. Also, when new features arrive, then we need to distinct in which Class to include it. Moreover, this is related to the Cohesion concept, which help us to group similar functions inside a Class, and that have the same purpose served by that Class. In conclusion, once you identify classes that have too many responsibilities, use this refactoring technique to create smaller classes with single responsibilities and focused only on one business actor. Use this principle as a tool when translating business software requirements into technical specifications. Programmers must understand these design decisions before programming. Now that you’ve learned the Single Responsibility principle, it’s time to learn the Open-closed principle to design flexible systems and avoid future software maintenance costs.  Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  "
    }, {
    "id": 37,
    "url": "http://localhost:4000/graphs-depth-first-search/",
    "title": "Graphs: Depth-First Search",
    "body": "2020/06/01 - Depth-First Search (DFS), is an algorithm to search for information in Graphs. A Graph is a non-linear data structure consisting of nodes (or vertices) and edges. Its shape depends on the physical or abstract problem we are trying to solve. For instance, if nodes represent cities, then the routes which connect cities may be represented by no-directed edges. But if nodes represent tasks to complete a project, then their edges must be directed to indicate which task must be completed before another. Graph theory was first proposed by Leonhard Euler when solved the Seven Bridges of Königsber problem. Graphs: Terminology: To describe terms related to Graphs, we use the following Graph, which models Hyperloop transport to be installed in Germany, for instance.  A Graph shows only the relationships between the vertices and the edges. Therefore, the most important here is to understand, which edges are connected to which vertex. Moreover, we can also say that Graph models connections between objects. Adjacency When two vertices are connected by a single edge, then they are adjacent or neighbors. In the figure above, the vertices represented by the cities Berlin and Leipzig are adjacent, but the cities Berlin and Dresden are not. Path A Path is defined as a sequence of edges. The figure above shows a path from Berlin to München, that passes through cities Leipzig and Nürnberg. Therefore, the path is Berlin, Leipzig, Nürnberg, München. Connected Graphs A graph is connected if exists at least one path from every vertex to every other vertex. Therefore, the figure above is connected because connects all cities. Directed and Weighted Graphs A graph is directed when the edges have a direction. In the figure above we have an undirected graph because the hyperloop can usually go either way. From Berlin to Leipzig is the same as from Leipzig to Berlin. A tree is an undirected graph, as long as any two vertices are connected by exactly one path. Graphs are called a weighted graph when edges are given weight. For instance, the distance between cities can be weighted in how fast they are connected. The edges may contain value/cost as well. Acyclic Graphs Versus Cyclic Graphs In Graphs, cycles are paths through edges and vertices that start and end at the same vertex. An acyclic graph has no such cycles. Reasons to use Graphs: One of the questions that a graph can answer is: which cities can be reached from a specified city?. Well, to respond to this question, we need to implement search algorithms. There are two different ways of searching in a graph: depth-first search (DFS) and breadth-first search (BFS). Depth-First Search (DFS): Depth-First Search (DFS) is an algorithm for traversing or searching for in a Graph. The algorithm starts at the root node (selecting some arbitrary city as the root node) and explores as far as possible along each path. The following Graph shows the sequence of cities followed by the DFS algorithm, if we choose Berlin as the root node, for instance.  Implementing Graphs Algorithm: We need an Object which supports any kind of data included in the Node (which includes the information, that we want to represent). We called it Vertex (because comes from a Mathematical concept). Moreover, to avoid searching in cycles, a boolean variable is included, so we will mark each node when we visit it. 123456789public class Vertex { private String name; private boolean visited; public Vertex(String name) {  this. name = name;  this. visited = false; }}To define, that two vertices are connected (through edges), we have two approaches: the adjacency matrix and the adjacency list. The Adjacency Matrix In a graph of N vertices, we create a two-dimensional array of NxN. An edge between two vertices (cities) indicates a connection (two adjacent nodes) and is represented by 1. No connections are represented by 0.  The table above says, Leipzig is adjacent to Berlin, Dresden, and Nürnberg, for instance. Create and Initialize an Abstract Data Type We create an Abstract Data Type called a Graph to define the behavior of our new data structure. We need a stack data structure so we can remember the visited vertices. A stack follows the last-in, first-out (LIFO) principle, i. e. , the city inserted at last is the first city to come out of the stack.  We define an arrayOfVertex[] array to store new Vertices(cities) added to the Graph. We define a numOfVertices variable that indicates the number of Vertices already added to the Graph. Since we will pass a String argument (city name) to our DFS algorithm, a mapOfVertex hashMap is defined to register the key-value: city-index, where the index is the City’s location at arrayOfVertex[]. 12345678910111213141516171819202122232425public class Graph { private final int MAX_VERTEX = 15; private Vertex arrayOfVertex[]; //cities private Map mapOfVertex; //matrix of adjacent vertex: private int matrixOfAdjVertex[][]; //register the location at the arrayOfVertex: private int numOfVertices; private Stack stack; public Graph() {  arrayOfVertex = new Vertex[MAX_VERTEX];  mapOfVertex = new ConcurrentHashMap&lt;&gt;();  numOfVertex = 0;  matrixOfAdjVertex = new int[MAX_VERTEX][MAX_VERTEX];  stack = new Stack&lt;&gt;();  //initialize matrix  for (int i = 0; i &lt; MAX_VERTEX; i++) {   for (int j = 0; j &lt; MAX_VERTEX; j++) {    matrixOfAdjVertex[i][j] = 0;   }  } }}Adding a Vertex Before the implementation, we create a Test case with the following assumption: 123456@Testpublic void test_addVertex() { Vertex city = new Vertex( Berlin ); graph. addVertex(city); assertTrue(graph. getMapOfVertex(). size() ==1);}The implementation code register the new city in our mapOfVertex hashMap. 1234public void addVertex(Vertex city) { mapOfVertex. put(city. getName(), numOfVertices); arrayOfVertex[numOfVertices++] =city;}The numOfVertices variable determines the location (index) of the new City in the arrayOfVertex[]. Adding an edge We add two entries to matrixOfAdjVertex, because two cities are connected in both directions. 123456public void addEdge(String city1, String city2) {  int start = mapOfVertex. get(city1);  int end = mapOfVertex. get(city2);  matrixOfAdjVertex[start][end] =1;  matrixOfAdjVertex[end][start] =1;}You can implement your code for these methods. The point here is that we need to define the topology of our Graph, adding Vertices(cities) and edges that connect them. Depth-First Search: The algorithm: We define a dfs() method, which receives the City name as its argument. Then we locate the index of this city in our hashMap, is marked as visited, and push it onto the stack. We iterate the stack until is empty. And this is what we do in every iteration:  We retrieve the Vertex from the top of the stack (peek) We try to retrieve at least one unvisited neighbor for this vertex If one vertex is found, it is marked as visited and pushes it onto the stack If one vertex is not found, we pop the stackIf Berlin were our entry city, then the first adjacent city will be Leipzig, which is marked as visited and push it into the stack. In the next iteration, we read Leipzig (through peek method) from the stack and look for its neighbors. Therefore, following these iterations, we arrive at München. That is the in-depth essence of this algorithm: to explore as far as possible along each branch before continuing with a new one. 123456789101112131415161718public void dfs(String city) {  int vertex = mapOfVertex. get(city);  arrayOfVertex[vertex]. setVisited(true);  System. out. print(city +    );  stack. push(vertex);  while (!stack. isEmpty()) {   int adjVertex = getAdjVertex(stack. peek());   if (adjVertex != -1) {    arrayOfVertex[adjVertex]. setVisited(true);    System. out. print(      arrayOfVertex[adjVertex]. getName() +    );    stack. push(adjVertex);   } else {    stack. pop();   }  } }12345678private int getAdjVertex(int vertex) {for (int adj=0; adj&lt;numOfVertices; adj++) {  if (matrixOfAdjVertex[vertex][adj] ==1 &amp;&amp;    arrayOfVertex[adj]. isVisited() ==false)    return adj; //return first adjacent vertex  }  return -1; //not vertices found}Test case 123456789101112131415161718192021222324252627282930313233@Test public void test_dfs() {  String city1 = Berlin ; String city2 = Leipzig ;  String city3 = Dresden ; String city4 = Nürnberg ;  String city5 = Hannover ; String city6 = Rostock ;  String city7 = Dortmund ; String city8 = Frankfurt ;  String city9 = Stuttgart ; String city10 = München ;  String city11 = Magdeburg ; String city12 = Bremen ;  graph. addVertex(new Vertex(city1));  graph. addVertex(new Vertex(city2));  graph. addVertex(new Vertex(city3));  graph. addVertex(new Vertex(city4));  graph. addVertex(new Vertex(city5));  graph. addVertex(new Vertex(city6));  graph. addVertex(new Vertex(city7));  graph. addVertex(new Vertex(city8));  graph. addVertex(new Vertex(city9));  graph. addVertex(new Vertex(city10));  graph. addVertex(new Vertex(city11));  graph. addVertex(new Vertex(city12));  graph. addEdge(city1, city2);  graph. addEdge(city2, city3);  graph. addEdge(city3, city4);  graph. addEdge(city4, city10);  graph. addEdge(city11, city5);  graph. addEdge(city5, city7);  graph. addEdge(city7, city8);  graph. addEdge(city8, city9);  graph. addEdge(city1, city6);  graph. addEdge(city1, city11);  graph. addEdge(city5, city12);  graph. dfs(city1); }Here, the output: 1Berlin Leipzig Dresden Nürnberg München Rostock Magdeburg Hannover Dortmund Frankfurt Stuttgart BremenWe can change the entry city and see different traversing paths 1Hannover Dortmund Frankfurt Stuttgart Magdeburg Berlin Leipzig Dresden Nürnberg München Rostock Bremen You can see as well the Breadth-First Search (BFS) algorithm by using an Adjacency List based on a LinkedList data structure in the following link "
    }, {
    "id": 38,
    "url": "http://localhost:4000/tree-data-structure-binary-search-tree/",
    "title": "Tree data structure: Binary Search Tree",
    "body": "2020/05/12 - Tree data structures are non-linear data structures, and they allow us to implement algorithms much faster than when using linear data structures. Tree: A tree is a data structure that consists of nodes connected by edges. Binary tree: A Binary tree can have two children: a left node and a right node. Every Node contains two elements: a key used to identify the data stored by the Node and a value that is the data contained in the Node. The following figure shows the binary tree terminology.  Binary search tree: The most common type of Binary tree is the Binary search tree, which has two main characteristics:  The value of the left Node must be lesser than the value of its parent.  The value of the right Node must be greater than or equal to the value of its parent. Moreover, you can search in a tree data structure quickly, as you can with an ordered array, and you can also insert and delete items quickly, as you can with a linked list. It takes a maximum of log2(N) attempts to find a value. As the collection of nodes gets large, the binary search tree becomes faster over a linear search which takes up to (N) comparisons. Tree data structure: Use Case:: The Global Trade Item Number (GTIN) can be used by a company to uniquely identify all of its trade items. The GTIN can be used to identify types of products that are produced by different manufacturers. A Webshop wants to retrieve information about GTINs efficiently by using a binary search algorithm. Solution: We create a Product Class which will be the data contained in a Node. 123456789public class Product { Integer productId; String name; Double price; String manufacturerName; .  //code omitted for brevity}We create a NodeP Class to store a list of Products. Moreover, this Class allows us to have two NodeP attributes to hold the left and right nodes. 123456789101112public class NodeP { private String gtin; private List&lt;Product&gt; data; private NodeP left; private NodeP right; public NodeP(String gtin, List&lt;Product&gt; data) {  this. gtin = gtin;  this. data = data; }} We create a new abstract data type called TreeP to define the behavior of our Binary Search Tree, which includes a NodeP root variable for the first element to be inserted. We need to implement an insert method, where every time a new GTIN is inserted, it compares the current GTIN versus the new GTIN. We store the new GTIN on the left or the right Node, depending on the result. In this way, the insert method maintains an ordered binary search tree. A Test case to verify our assumptions: 12345@Testpublic void when_rootNull_inserNode() { tree. insert( 04007801321224 , new ArrayList&lt;&gt;(Arrays. asList(product1))); assertTrue(tree. getRoot() != null);}And here the implementation for the insert method: 1234567891011121314151617181920212223242526272829303132333435public class TreeP { private NodeP root; public void insert(String gtin, List&lt;Product&gt; data) {  NodeP newNode = new NodeP(gtin, data);  if (root == null)   root = newNode;  else {   NodeP current = root;   NodeP parent;   while (true) {    parent = current;    if (gtin. compareTo(current. getGtin()) &lt; 0) {     current = current. getLeft();     if (current == null) {      parent. setLeft(newNode);      return;     }    } else if (gtin. compareTo(current. getGtin()) &gt; 0) {     current = current. getRight();     if (current == null) {      parent. setRight(newNode);      return;     }    } else     current. setData(data);     return; //already exists   }  }  return; }}Create a Test case for a find method: 12345678910111213141516171819@Testpublic void test_findNode() { tree. insert( 04000345706564 ,  new ArrayList&lt;&gt;(Arrays. asList(product1))); tree. insert( 07611400983416 ,   new ArrayList&lt;&gt;(Arrays. asList(product2))); tree. insert( 07611400989104 ,   new ArrayList&lt;&gt;(Arrays. asList(product3, product4))); tree. insert( 07611400989111 ,  new ArrayList&lt;&gt;(Arrays. asList(product5))); tree. insert( 07611400990292 ,  new ArrayList&lt;&gt;(Arrays. asList(product6, product7, product8))); assertEquals(null, tree. find( 07611400983324 )); tree. insert( 07611400983324 ,  new ArrayList&lt;&gt;(Arrays. asList(product9))); assertTrue(tree. find( 07611400983324 ) != null); assertEquals( 07611400983324 ,   tree. find( 07611400983324 ). getGtin());}And here is the implementation that shows a find method (the gtin parameter is our key), which iterates through all nodes until a GTIN is found. This algorithm reduces the search space to N/2 because the binary search tree is always ordered. 1234567891011121314151617public NodeP find(String gtin) { NodeP current = root; if (current == null)  return null; while (!current. getGtin(). equals(gtin)) {  if (gtin. compareTo(current. getGtin()) &lt; 0) {   current = current. getLeft();  } else {   current = current. getRight();  }  if (current == null) //not found in children   return null; } return current;}This Binary Search Tree works well when the data is inserted in random order. Therefore, when the values to be inserted are already ordered, a binary tree becomes unbalanced. With an unbalanced tree, we can not find data quickly. One approach to solving unbalanced trees is the red-black tree technique, which is a binary search tree with some special features. Assuming that we already have a balanced tree, the following algorithm shows us how fast in terms of comparisons could be a binary search tree which depends on a number N of elements. For instance, in 1 billion products, to find a product by GTIN, the algorithm needs only 30 comparisons. See Big O Notation. 1234567@Testpublic void whenNelements_return_NroComparisons(){ assertTrue(treePerformance. comparisons(15) &lt;= 4); assertTrue(treePerformance. comparisons(31) &lt;= 5); assertTrue(treePerformance. comparisons(1000) &lt;=10); assertTrue(treePerformance. comparisons(1000000000) &lt;=30);}And here is our implementation. 12345678910111213141516public class TreePerformance { public static int comparisons(int N) {  int acumElements = 0;  int comparisons = 0;  for (int level = 0; level &lt;= N / 2; level++) {   int power = (int) Math. pow(2, level);   acumElements += power;   if (acumElements &gt;= N) {    comparisons = ++level;    break;   }  }  System. out. println( comparisons -&gt;   + comparisons);  return comparisons; }}Understanding the inner workings of common data structures and algorithms is a must for Java developers. Learn more "
    }, {
    "id": 39,
    "url": "http://localhost:4000/optimize-online-purchases/",
    "title": "Learning Test-Driven Development",
    "body": "2020/04/09 - Test-driven development (TDD) is a development approach that emphasizes writing a test before writing the necessary code and then refactoring the code to optimize it. Problem: Optimize a basket in online purchases means fill a basket with the most valuable goods under a given budget. Imagine that we have a budget of 4 US$ and we want to buy the most valuable snacks from the following table: But who decides if a product is more valuable than another one? Well, this depends on every business. It could be an estimation based on quantitative or qualitative analysis. For instance, for our solution, we choose a quantitative approach based on which product gives us more grams per every dollar invested. Optimize a basket in online purchases: Solution: To implement our algorithm to optimize a basket in online purchases, we use the Red-Green Refactor technique, which is the basis of test-drive-development (TDD). Firstly, in every assumption, we will write a test and see if it fails. Secondly, we write the code that implements only that test and sees if it succeed, then we can refactor the code to make it better. Finally, we continue with another assumption and repeat the previous steps until the algorithm is successfully implemented for all tests. To generalize the concept of “the most valuable product” we assign a value to every product. Our algorithm receives two parameters: an array 2-D which includes [product-id][price][value] and the budget. Assumption #1 – Given an array of products ordered by value, return the most valuable products We start defining a java test creating a new BasketOptimized class. For naming variables, you can read clean code. 12345678910111213141516171819202122232425262728public class BasketOptimizedTest { BasketOptimized basketOptimized; @Before public void setup() {  basketOptimized = new BasketOptimized(); } @Test public void productsOrderedByValue () {  double[][] myProducts = new double[][] {    {1, 0. 98, 230},    {2, 0. 98, 230},    {3, 0. 48, 75},    {4, 1. 29, 55},    {5, 1. 29, 47},    {6, 4. 86, 14},    {7, 1. 69, 12},  };  double[][] mostValueableProducts =    basketOptimized. fill(myProducts, 4);  assertEquals(590d,    Arrays. stream(mostValueableProducts).       mapToDouble(arr -&gt; arr[2]). sum(),0); }}The first time, it should fail because the fill method doesn’t exist. Then we need to create an easy implementation to pass the test: the sum of the values must be equal to 590 because this represents all selected products which its prices sum less or equal than 4. Now, we proceed to implement the fill method. 12345678910111213141516171819202122public class BasketOptimized { public double[][] fill(double[][] myProducts, double budget) {  int len = myProducts. length;  double[][] mostValueableProducts = new double[len][3];  double sum = 0;  for (int idx=0; idx &lt; len; idx++) {   sum = sum + myProducts[idx][1]; //price   if (sum &lt;= budget) {    mostValueableProducts[idx][0] =      myProducts[idx][0]; //id    mostValueableProducts[idx][1] =      myProducts[idx][1]; //price    mostValueableProducts[idx][2] =      myProducts[idx][2]; //value   }  }  return mostValueableProducts; }}Assumption #2 – Given an array of products not ordered by value, return the most valuable products In this case we pass a not ordered array, so we can see that our new test will fail. 123456789101112131415161718@Testpublic void productsNotOrderedByValue () { double[][] myProducts = new double[][]{   {1, 0. 98, 230},   {2, 1. 29, 47},   {3, 1. 69, 12},   {4, 1. 29, 55},   {5, 0. 98, 230},   {6, 4. 86, 14},   {7, 0. 48, 75} }; double[][] mostValueableProducts   = basketOptimized. fill(myProducts, 4); assertEquals(590d, Arrays. stream(mostValueableProducts)  . mapToDouble(arr -&gt; arr[2]). sum(), 0);} Any software design is generally a matter of opinion. There is no definitive Guide. – codersite. dev Here’s a Quick Guide to Elevate Your Projects with Proven Software Design Tactics!.  We realize that we need to order the array by value because we want the most valuable products, so its time to refactor our algorithm. What we need to do is to sort our input array. 123456public double[][] fill(double[][] myProducts, double budget) { Arrays. sort(myProducts, Collections. reverseOrder(   Comparator. comparingDouble(a -&gt; a[2]))); int len = myProducts. length; double[][] mostValueableProducts = new double[len][3];Then we can see our two test cases were successful. Calculate combinations: Assumption #3 – Given an array of products, we need to obtain the most valuable products from all possible combinations of the products Imagine the following escenario: 123456789101112131415double[][] myProducts = new double[][] {        {1, 0. 98, 230},        {2, 0. 51, 30},        {3, 0. 49, 28},        {4, 1. 29, 55},        {5, 0. 98, 230},        {6, 4. 86, 14},        {7, 0. 48, 75},    };double[][] mostValueableProducts = basketOptimized    . fill(myProducts, 4);assertEquals(590d,   Arrays. stream(mostValueableProducts)    . mapToDouble(arr -&gt; arr[2]). sum(),0);The test is expecting a result of 590 which corresponds to the final price of 3,73US$ (0. 98+0. 98+0. 48+1. 29). Once the algorithm sort by value the input array, we have the following result: 1234567[1. 0, 0. 98, 230. 0][5. 0, 0. 98, 230. 0][7. 0, 0. 48, 75. 0][4. 0, 1. 29, 55. 0][2. 0, 0. 51, 30. 0][3. 0, 0. 49, 28. 0][6. 0, 4. 86, 14. 0] But here we realize the exists another combination of products which give us the most valuable products: 230+230+75+30+28 = 593 which corresponds to the final price of 3,44US$. Then we need to refactor our code to calculate all combinations (subsets) and return the most valuable products under a budget of 4 US$. The subsets can be represented by all the binary options from 0 to 7 (the array size). 12345670000 = {}0001 = { {1, 0. 98, 230} }0010 = { {2, 0. 51, 30} }0011 = { {1, 0. 98, 230}, {2, 0. 51, 30} }. . . We build a hashMap to store all combinations and the sum of its values. Finally, we return the first element of the hashMap ordered by value 123456789101112131415161718192021int len = myProducts. length;int numIterations = (int) Math. pow(2, myProducts. length);Map&lt;double[][], Double&gt; combinations = new HashMap&lt;&gt;();for (int idx=0; idx&lt;numIterations; idx++){ double[][] combx = new double[len][]; double sumPrice = 0; double sumValue = 0; int i = 0; for (int idx2=0; idx2&lt;len; idx2++) {  if ((idx &amp; (int) Math. pow(2, idx2)) == 0) {    combx[i++] = myProducts[idx2];    sumPrice = sumPrice + myProducts[idx2][1];    sumValue = sumValue + myProducts[idx2][2];  } } if (combx. length &gt; 0 &amp;&amp; sumPrice &lt;= budget) {   combinations. put(combx, Double. valueOf(sumValue)); }}You can see the complete solution explained in detail and all test cases in this link "
    }, {
    "id": 40,
    "url": "http://localhost:4000/given-positive-number-n-find-smallest-number-same-number-digits/",
    "title": "Given N, find the smallest number with the same digits",
    "body": "2019/06/29 - Write a method that, given an original number N, returns the smallest number with the same number of digits. For instance, given N=4751, the method returns 1000. Given N=100, the method should return 100. Given N=1, the method should return 0. Maybe the first idea comes to our minds could be to iterate from the given original number and decrease one by one, and in every iteration to check if every new number contains one digit less than the original number, if the answer is true, then the previous one is the smallest number. Define a test case to validate what your code will do: Our assumption based on a test case: 12345678910111213141516public class SmallestNumberTest { @Test public void test_right_smallest_values() {  assertTrue(NumberUtils. smallest(4751) == 1000);  assertTrue(NumberUtils. smallest(189) == 100);  assertTrue(NumberUtils. smallest(37) == 10);  assertTrue(NumberUtils. smallest(1) == 0); } @Test public void test_wrong_smallest_values() {  assertFalse(NumberUtils. smallest(8) == 1);  assertFalse(NumberUtils. smallest(2891) == 2000); }}Here, is the implementation code that works for positive numbers: 1234567891011121314151617public class NumberUtils { public static int smallest(int N) {  int smallestNumber = 0;  if (N &lt;= 1)   return smallestNumber;    int numberOfDigitsOriginalN = String. valueOf(N). length();  while (N &gt; 0) {   N--;   if (String. valueOf(N). length() ==     (numberOfDigitsOriginalN -1)) {    return ++N;   }  }  return smallestNumber; }}If we realize, the solution follows a common pattern: N = 3891 -&gt; smallest number = 1000 N = 189 -&gt; smallest number = 100 N = 37 -&gt; smallest number = 10 The smallest number is a power of 10, where the exponent is: (number of digits of the given N – 1) If we want to include negative numbers, we must consider the smallest number with the same number of digits and the same sign. We add our test case for negative numbers as well: 12345@Test public void test_right_smallest_values() { assertTrue(NumberUtils. smallest4(-1) == -9); assertTrue(NumberUtils. smallest4(-37) == -99);}Here, is the algorithm for positive and negative numbers: 12345678910111213public class NumberUtils { public static int smallest(int N) {  int numberOfDigits = (int) String. valueOf(Math. abs(N)). length();  if (N &gt;= 0) {   if (numberOfDigits == 1) {    return 0;   } else {    return (int) Math. pow(10, numberOfDigits - 1);   }  } else   return 1 - (int) Math. pow(10, numberOfDigits); }}The main idea in Analysis of Algorithms is always to improve the algorithm performance by reducing the number of steps and comparisons. The simpler and more intuitive an algorithm is, the more useful and efficient it will be. Similar questions you can find in my book about algorithms and data structures. Learn how to apply common algorithms to the practical problems.  "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});